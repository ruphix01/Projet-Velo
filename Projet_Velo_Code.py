# -*- coding: utf-8 -*-
"""Projet_Tricycle_Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fBS9Al1SPjW655VXGErHcNehsfYkvbRX

# **Code_Projet Tricycle**

# ❌ Ne pas éxécuter  
# Préprocessing et création du dataset

La première chose que nous faisons est de créer un dataset comprenant l'ensemble de nos sources de données (trafic routier et vélo, données météo, transport en commun, ...) afin de pouvoir les analyser et implémenter dans nos modèles de Machine Learning.

Nous utiliserons une base 'jour' afin de pouvoir les compiler.

## Preprocessing Données de trafic routier - Compteurs permanents Paris 2021

Pour pouvoir compiler les données de trafic par compteur classique, nous avons compilé les résultats de dizaines de millions de mesures horaires sur l'année dispatchées en 58 fichiers correspondants à peu près aux semaines de l'année.

Nous avons regroupé les données par jour. Pour cela, nous avons implémenté une boucle pour traiter tous les fichiers à la suite afin de tout compiler dans un seul dataframe. 

Cette boucle nous permet d’obtenir pour chaque jour de l’année :
- La somme totale du trafic routier sur une journée (somme des débits horaires par capteurs et par jour)
- Le nombre total de mesures effectuées par tous les capteurs sur une journée (une unité de compte = une heure pour un capteur)
- La moyenne du trafic par heure et par capteur (somme totale du trafic divisé par le nombre d'unités de compte sur une journée).
"""

#On crée une fonction qui nous permet de renommer les fichiers et de les insérer dans une liste
liste_nomfichier = []
def nomfichier(a,b) :
    count = 1
    for x in range(0,59) :
        c = a+str(count)+b
        liste_nomfichier.append(c)
        count += 1

nomfichier("trafic_capteurs_2021_W (", ").txt")

#On crée une nouvelle fonction qui va traiter les fichiers en boucle et remplir un DataFrame vide avec les données.
resultfinal = pd.DataFrame(columns=['day','q','count'])
def compilation(a) : 
        global resultfinal
        for x in a :
            # On lit chaque fichier de la liste
            df_temp = pd.read_table(r"C:\Users\admin\Desktop\Tricycle\Traffic 2021 par semaine/"+x, sep = ";")
            # On transforme la variable str qui contient la date au bon format
            df_temp["t_1h"] = pd.to_datetime(df_temp["t_1h"])
            # On crée une variable day qui contient le numéro du jour de l'année (1 à 365)
            df_temp["day"] = df_temp["t_1h"].apply(lambda x: x.strftime('%j'))
            # On définit les fonctions à appliquer puis on groupe en fonction du jour de l'année
            funct = {"q" : "sum", "day" : "count"}
            df_temp2 = df_temp[df_temp["t_1h"].dt.year == 2021].groupby("day").agg(funct)
            # On renomme les colonnes et on fixe un nouvel index (sinon deux variables "day")
            df_temp2 = df_temp2.rename(columns = {"day":"count"}) 
            df_temp2 = df_temp2.reset_index()
            # On regroupe les données dans le DataFrame final en sommant les variables pour un "day" identique
            resultfinal = pd.concat([resultfinal, df_temp2]).groupby(['day']).sum().reset_index()

#On compile l'ensemble des données.
compilation(liste_nomfichier)

"""## Preprocessing Données infrarouges (vélos et autres modes de transport) Paris 2021

Nous nous attaquons ensuite aux données de trafic infrarouge

Pour les intégrer à notre dataframe, nous avons créé une variable "date" et une variable "day" au bon format.

Par la suite, afin de bien différencier les modes de transports motorisés et les mobilités douces (vélos, trotinettes), nous les avons regroupés sous deux variables ("Motorisé" et "velo").
Nous avons également calculé la somme et la moyenne des comptages .
Pour finir, nous avons extrait notre dataframe pour le fusionner avec les autres sur la variable 'day'
"""

#On lit le dataframe et on renomme les colonnes
df_infra = pd.read_table(r"C:\Users\admin\Desktop\Tricycle/comptage-multimodal-comptages.csv", sep = ";")
df_infra.rename(columns={'Date et heure de comptage': 'Date', 'Mode déplacement': 'Mode', 'Nombre de véhicules': 'q'}, inplace=True)

#On clean la variable Date et on crée une variable numéro de jour
df_infra["Date2"] = df_infra["Date"].apply(lambda x: x.split("T")[0])
df_infra["Date2"] = df_infra["Date"].apply(lambda x: x.split("+")[0])
df_infra["Date2"] = pd.to_datetime(df_infra["Date2"])
df_infra["day"] = df_infra["Date2"].apply(lambda x: x.strftime('%j'))

# On recode la variable mode de transport pour ne conserver que les modes motorisés.
df_infra["Mode"].value_counts()

def recodemode(a) :
        if (a == "Trottinettes + vélos" or a == "Vélos" or a == "Trottinettes") :
            return "Non"
        else :
            return "Oui"

df_infra["Motorisé"] = df_infra["Mode"].apply(recodemode)
df_infra["Motorisé"][df_infra["Date2"].dt.year == 2021].value_counts()

# On crée un DataFrame uniquement pour les modes motorisés sur 2021.
df_infra2021 = df_infra[df_infra["Motorisé"] == "Oui"]
df_infra2021 = df_infra2021[df_infra2021["Date2"].dt.year == 2021]

# On crée un DataFrame qui somme la fréquentation et le nombre de comptage  et qui en fait la moyenne.
funct = {"q" : "sum", "day" : "count"}
df_infra_final = df_infra2021.groupby("day").agg(funct)
df_infra_final = df_infra_final.rename(columns = {"day":"count_infra", "q":"q_infra"}) 
df_infra_final = df_infra_final.reset_index()
df_infra_final["mean_infra"] = df_infra_final["q_infra"]/df_infra_final["count_infra"]

# On merge les deux dataFrames de moyenne
df_total = df_trafic_final.merge(df_infra_final, on = "day", how = "inner")

# On mesure la corrélation entre mean_trafic et mean_infra
from scipy.stats import pearsonr

pearsonr(df_total["mean_trafic"],df_total["mean_infra"])

df_total.plot.scatter(x='mean_trafic', y='mean_infra', s=30);
sns.lmplot(x = 'mean_trafic', y = 'mean_infra', data = df_total);

# On crée un dataFrame uniquement pour les modes vélo sur 2021
df_infra_velo2021 = df_infra[df_infra["Motorisé"] == "Non"]
df_infra_velo2021 = df_infra_velo2021[df_infra_velo2021["Date2"].dt.year == 2021]

# On crée un dataFrame qui somme la fréquentation et le nombre de comptage  et qui en fait la moyenne.
funct = {"q" : "sum", "day" : "count"}
df_infra_final_velo = df_infra_velo2021.groupby("day").agg(funct)
df_infra_final_velo = df_infra_final_velo.rename(columns = {"day":"count_infra_velo", "q":"q_infra_velo"}) 
df_infra_final_velo = df_infra_final_velo.reset_index()
df_infra_final_velo["mean_infra_velo"] = df_infra_final_velo["q_infra_velo"]/df_infra_final_velo["count_infra_velo"]
df_infra_final_velo.head()

# On merge tous les dataFrames.
df_total_ok = df_total.merge(df_infra_final_velo, on = "day", how = "inner")
df_total_ok.head()
df_total_ok.to_csv(r'C:\Users\admin\Desktop\Tricycle/trafic_2021_infra_et_traffic.csv', index=False)

"""## Preprocessing Données de compteurs vélo Paris 2021

Concernant les données issues des capteurs vélo, nous avons pu exporter les données directement sur l'année 2021 au complet.

Il nous a donc suffit de créer une variable "Date" puis "day" au bon format, et de supprimer les variables inutiles, pour pouvoir ajouter ces données à notre dataframe (via la méthode merge()).

Nous avons également ajouté une variable "mean_velo_compteur", qui est la somme des comptages vélo sur une période, divisée par le nombre de borne de comptage.
"""

#On intègre le fichier données vélo compteur.
df_velo = pd.read_table(r"C:\Users\admin\Desktop\Tricycle/Données vélo - Données de compteur.csv", sep = ",")

#On change le format de la variable 'Date' et on crée la variable 'day'.
df_velo["Date2"] = pd.to_datetime(df_velo["Date"])
df_velo["day"] = df_velo["Date2"].apply(lambda x: x.strftime('%j'))

#On calcule la moyenne du nombre de vélo sur 1/4 d'heure et on divise par le nombre de compteurs
df_velo["mean_velo_compteur"] = df_velo_compteur["sum_velo_compteur"]/df_velo["count_velo_compteur"]

#On merge les données
df_total_ok_velo = df_total_ok.merge(df_velo, on = "day", how = "inner")

"""## Preprocessing Données météo 2021

De même, il a été aisé pour nous de télécharger les données météo de Paris sur l'année 2021.
Nous avons simplement créé une variable "Date" et une variable "Day" pour pouvoir ajouter les variables à notre dataframe.
"""

#On intègre le fichier météo 2021.
df_meteo = pd.read_table(r"C:\Users\admin\Desktop\Tricycle/export-paris2021.csv", sep = ",")

#On clean la variable Date et on crée une variable 'day'.
df_meteo["Date2"] = pd.to_datetime(df_meteo["DATE"])
df_meteo["day"] = df_meteo["Date2"].apply(lambda x: x.strftime('%j'))

#On merge avec les données de trafic
df_complet = df_total_ok_velo_valid.merge(df_meteo, on = "day", how = "inner")

"""## Preprocessing Données de validation des transports en commun 2021

Concernant les données de validation des transports en commun, il nous a fallu :
*   Pour le réseau de surface, concaténer les 4 datasets à notre disposition (un par trimestre) sur l'axe 0 afin d'obtenir une année complète.
*   Pour le réseau ferré, concaténer les 2 datasets à notre disposition (un par semestre) de la même façon.

Nous avons ensuite, comme pour les données de compteurs vélo et de météo, créé une variable "Date" et une variable "day" pour pouvoir ajouter les variables à notre dataframe.

Enfin, nous avons créé une variable "sum_total_valid" qui est la somme des validations sur le réseau ferré et le réseau de surface sur une période.
"""

#On intègre le fichier données de validation.
df_valid = pd.read_table(r"C:\Users\admin\Desktop\Tricycle/validation_2021_V2.csv", sep = ",")

#On clean la variable Date et on crée une variable 'day'.
df_valid["Date2"] = pd.to_datetime(df_valid["Date"])
df_valid["day"] = df_valid["Date2"].apply(lambda x: x.strftime('%j'))

#On calcule la somme des validation du réseau ferré + du réseau de surface
df_valid[sum_total_valid] = df_valid[sum_ferre_valid] + df_valid[sum_surface_valid] 

#On merge l'ensemble des données
df_total_ok_velo_valid = df_total_ok_velo.merge(df_valid, on = "day", how = "inner")

"""## Ajout de variables temporelles

Pour faciliter notre analyse et nos visualisations, nous avons ajouté un certain nombre de variables temporelles à notre dataframe :
"""

#Ajout d'un variable 'weekday', précisant le jour de la semaine (lundi, mardi, ...)
df['date'] = pd.to_datetime(df.date)
df['weekday'] = df['date'].dt.day_name()

#On ajoute une colonne précisant s'il s'agit d'un jour de la semaine ou du week-end
df["IsWeekend"] = df["date"].dt.weekday >= 5

#On ajoute une colonne précisant le mois
df['Mois'] = df.date.dt.month
df['Nom_mois'] = df.date.dt.month_name()

#On ajoute une colonne précisant le numéro de la semaine en question.
df["date"] = pd.to_datetime(df["date"])
df["numsem"] = df["date"].agg(lambda x : x.isocalendar()[1])
df["numsem"][0:3] = 1

#On met la variable 'date' au format jour/mois/année
df['date'] = pd.to_datetime(df['date'])
df['date'] = df['date'].apply(lambda x: x.strftime('%d/%m/%Y'))

"""Nous avons également ajouté une variable ‘typejour’ = une variable catégorielle qui divise les jours de l’année en : jours de vacances scolaires, jours fériés (hors vacances), weekend (hors vacances) et jours de la semaine (hors vacances). A noter que cette variable n’a pas été créée via une formule mais fusionnée au dataframe sous excel après avoir été codée à la main.

A l'issue de ces étapes de preprocessing, un nouveau dataframe est obtenu, compilant l'ensemble des données.
Etant donné la durée de traitement du code, nous avons exporté ce dataframe sous le nom "DataFrame_tricycle.csv" afin d'alléger ce notebook.

# 🌞 Charger "DataFrame_tricycle.csv" et éxécuter à partir d'ici 
# Import des données et des packages
"""

# Commented out IPython magic to ensure Python compatibility.
#Importation des packages nécessaires à l'analyse
# %matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from datetime import datetime, timedelta

from sklearn.exceptions import ConvergenceWarning
import warnings
from sklearn.exceptions import DataConversionWarning
warnings.filterwarnings(action='ignore', category=ConvergenceWarning)

#On importe notre dataframe
df = pd.read_csv("/content/DataFrame_tricycle.csv", sep=";")

# Visualisation du dataframe modifié
df.head()

"""## Ajout de colonnes de calculs comptage

*** Expliquer les calculs qui suivent et leurs objectifs + le placer dans la partie pré-processing***
"""

# Création des variables "part du vélo dans le trafic" sur une base moyenne horaire commune :

# On divise le total de la fréquentation quotidienne des TC par 24 pour obtenir la moyenne horaire
df["mean_total_valid"] = df["sum_total_valid"]/24

# Pour obtenir la par du vélo dans le trafic par source de donnée :
# On divise la moyenne vélo horaire par la somme de toutes les moyennes horaires des différentes modes (mea_velo compteur est multiplié par 4 car c'est l'expression d'une moyenne par quart d'heure)
df["part_velo_compteur"] = (df["mean_velo_compteur"]*4) / ((df["mean_velo_compteur"]*4) + df["mean_trafic_compteur"] + (df["sum_total_valid"]/24)) * 100
df["part_velo_infra"] = df["mean_velo_infra"] / (df["mean_velo_infra"] + df["mean_trafic_infra"] + (df["sum_total_valid"]/24)) * 100

"""## Nettoyage du dataset

Nous nettoyons les données du dataframe, en passant tous les noms de colonne en minuscule et en remplaçant les caractères spéciaux par des caractères classiques.
"""

# On passe tous les noms de colonne en minuscule
df.columns = df.columns.str.lower()

#On remplace les caractères invalides présents dans la colonne "opinion" par les lettres correspondantes
df.opinion = df.opinion.str.replace("Ã©", "é")
df.opinion = df.opinion.str.replace("Ã¨", "è")

"""# Analyse Exploratoire des données

Nous avons ensuite inspecté nos données pour s'assurer de leur validité, de leur précision et de leur cohérence, à la fois sur la forme et sur le fond.

## Analyse de la forme des données
"""

# le data frame est composé de 365 lignes et 53 variables

df.shape

# On calcul le nombre de chaque catégorie de variables en fonction de leur type

print(f"Types de variables présentes dans le dataframe : \n\n{df.dtypes.value_counts()}")

"""## Valeurs manquantes et doublons"""

# Visualisation des valeurs manquantes
print(f" Valeurs manquantes contenues dans le dataframe = {df.isna().sum().sum()}")

# Visualisation des doublons
print(f" Doublons contenus dans le dataframe = {df.duplicated().sum()}")

"""# Détermination de la variable cible

A ce stade, nous pouvons connaître la fréquentation vélo grâce à 2 types de données :
- les données multimodales issues des capteurs infrarouges
- les données de trafic routier et vélo issues des capteurs classiques

Nous cherchons donc à déterminer lesquelles seront les plus pertinentes à utiliser dans notre modélisation. Ci-dessous quelques premières visualisations qui permettent de comparer les deux mesures :
"""

#On instance une carte de couleur
my_cmap = plt.get_cmap("viridis")

#On instance une figure
plt.figure(figsize = (20,10))
#On compare la moyenne du trafic vélo (via compteurs permanents) et la moyenne du trafic vélo + trotinnettes (via capteurs infra) via un nuage de points
plt.subplot(221)
plt.scatter("mean_velo_compteur", "mean_velo_infra",c = 'mois', cmap = "viridis" , data = df)
plt.plot((df.mean_velo_compteur.min(), df.mean_velo_compteur.max()),(df.mean_velo_infra.min(), df.mean_velo_infra.max()))

#On ajoute les légendes
plt.xlabel("Données de trafic vélo (compteur)")
plt.ylabel("Données de trafic vélo (infrarouge)")
plt.title("Trafic vélo")
plt.suptitle("Comparaison des données de compteur vs caméra infrarouge par mode", fontsize = 25);

#On crée une figure et on compare la moyenne du trafic routier (via compteurs permanents) et la moyenne du trafic routier (via capteurs infra) via un nuage de points
plt.subplot(222)
plt.scatter(x = "mean_trafic_compteur", y = "mean_trafic_infra", c = 'mois', cmap = "viridis", data = df )
plt.plot((df.mean_trafic_compteur.min(), df.mean_trafic_compteur.max()),(df.mean_trafic_infra.min(), df.mean_trafic_infra.max()))
#On ajoute les légendes
plt.xlabel("Données de trafic routier (compteur)")
plt.ylabel("Données de trafic routier (infrarouge)")
plt.title("Trafic routier");

#On compare ensuite la moyenne du trafic par mois pour le trafic routier et vélo, sur les données de compteurs et les données infra

#On instance une figure et on crée 4 graphiques en barre avec leurs légendes
plt.figure(figsize = (15,15))
plt.subplot(223)
plt.bar("nom_mois", "mean_trafic_compteur", data = df, color = 'tab:blue' )
plt.xticks(rotation = 60)
plt.title("Trafic routier par mois (compteur en veh. /h)")

plt.subplot(224)
plt.bar("nom_mois", "mean_trafic_infra", color = "tab:red", data = df)
plt.title("Trafic routier par mois (infrarouge en veh. /h)")
plt.xticks(rotation = 60)

plt.subplot(221)
plt.bar("nom_mois", df["mean_velo_compteur"]*4, data = df, color = 'tab:blue')
plt.title("Trafic vélo par mois (compteur en velo/h)")
plt.xticks(rotation = 60)

plt.subplot(222)
plt.bar("nom_mois", "mean_velo_infra", data = df ,color = "tab:red")
plt.title("Trafic vélo par mois (infrarouge en velo/h)")
plt.xticks(rotation = 60)
plt.suptitle("Trafic moyen par mois par mode", fontsize = 20);

#Enfin, on compare le nombre de comptages par mois selon le mode de comptage

#On instance une figure et on crée 4 graphiques en barre avec leurs légendes
plt.figure(figsize = (15,15))
plt.subplot(223)
plt.bar("nom_mois", "count_trafic_compteur", data = df, color = 'tab:blue' )
plt.xticks(rotation = 60)
plt.title("Comptage routier total par mois (compteur)")

plt.subplot(224)
plt.bar("nom_mois", "count_trafic_infra", color = "tab:red", data = df)
plt.title("Comptage routier total par mois (infrarouge)")
plt.xticks(rotation = 60)

plt.subplot(221)
plt.bar("nom_mois", "count_velo_compteur", data = df, color = 'tab:blue')
plt.title("Comptage vélo total par mois (compteur)")
plt.xticks(rotation = 60)

plt.subplot(222)
plt.bar("nom_mois", "count_velo_infra", data = df ,color = "tab:red")
plt.title("Comptage vélo total par mois (infrarouge)")
plt.xticks(rotation = 60)
plt.suptitle("Volume de comptage par mois par mode", fontsize = 20);

"""Par ailleurs, pour vérifier s'il existe une différence importante entre les deux types de comptage pour expliquer la part du vélo dans l'ensemble des déplacements (routier, transports en communs et vélo) à Paris, nous avons comparé la part du vélo mesurée par capteurs infrarouges et la part du vélo mesurée par les capteurs permanents :"""

#On importe FuncFormatter depuis matplotlib.ticker
from matplotlib.ticker import FuncFormatter
import matplotlib.ticker as mtick

#Comparaison de la part trafic vélo mensuelle issue des données infrarouge vs des compteurs
fig, ax1 = plt.subplots(figsize = (20,9))  
color = 'tab:red'

ind_s = np.arange(len(set(df.numsem))) #indice hebdo
ind_m = np.arange(len(set(df.mois))) #indice mensuel

#width = 0.35  

#On ajoute les légendes
ax1.set_xlabel('mois')  
ax1.set_ylabel('part du trafic vélo (infrarouge)', color = color)  
ax1.plot(ind_s, df.part_velo_infra.groupby(df["numsem"]).mean(),  color = color, linewidth=3, marker = 'o', markersize = 7 ) #line hebdo
#ax1.plot(ind_m, df.mean_velo_infra.groupby(df["mois"]).mean(),  color = color, linewidth=3 )  #line mensuelle


# on instancie une liste qui divise l'année en 12 segments relatifs aux 52 semaines pour positionner nos labels sur l'abscisse
liste_mois = []
y = 0
for x in range(0,12) :
  liste_mois.append(y)
  y = y + (52/12)

#On ajoute les légendes
ax1.tick_params(axis ='y', labelcolor = color)  
ax1.grid(axis = "x", linestyle='dotted')
plt.xticks( liste_mois ,['Jan', 'Fev', 'Mar', 'Avr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] ) #axe hebdo
#plt.xticks( [0,1,2,3,4,5,6,7,8,9,10,11],['Jan', 'Fev', 'Mar', 'Avr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] ) #axe mensuel

ax2 = ax1.twinx()  

#On ajoute les légendes
color = 'tab:blue'
ax2.set_ylabel('part du trafic vélo (compteur)', color = color)  
ax2.plot(ind_s, df["part_velo_compteur"].groupby(df["numsem"]).mean(),  color = color, linewidth=3, marker = 'o', markersize = 7 ) #line hebdo
#ax2.plot(ind_m, df["mean_velo_compteur"].groupby(df["mois"]).mean(),  color = color, linewidth=3 ) #line mensuelle

#On reformate les étiquettes de l'axe des ordonnées en pourcentage
ax2.tick_params(axis ='y', labelcolor = color)  
ax1.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))
ax2.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))

plt.title('Comparaison de la part trafic vélo hebdomadaire issue des données infrarouge vs des compteurs', fontweight ="bold")  
  
plt.show();

"""# Analyse de la variable cible"""

# Examen de la variable cible (target)
df['mean_velo_compteur'].describe()

#On crée un boxplot de la variable cible pour en analyser la distribution
plt.figure(figsize = (7, 7))
plt.boxplot((df.mean_velo_compteur))

#On ajoute les légendes
plt.title('Boxplot de la variable cible (mean_velo_compteur)')
plt.ylabel("Moyenne de comptage vélos par 1/4 d'heure")
plt.axes([0.65, 0.65, 0.2, 0.15], facecolor='#ffe5c1')
plt.hist(df.mean_velo_compteur, color='#FFC575')
plt.xlabel('Distribution');

#On crée un bloxpot de la variable cible par mois pour en analyser la distribution

#On crée une boucle qui ajoute un mois après l'autre
l=list()
for i in df.mois.unique():
    l.append(df[df['mois'] == i]['mean_velo_compteur'])
plt.figure(figsize = (15,7))
plt.boxplot(l)

#On ajoute les légendes
plt.xticks(range(1,13),df.mois.unique())
plt.xlabel("Mois")
plt.ylabel("Moyenne de comptage vélos par 1/4 d'heure")
plt.title("Boxplot de la variable cible (mean_velo_compteur) par mois")
plt.show();

#Comparaison de la part trafic vélo mensuelle issue des données infrarouge vs des compteurs
fig, ax1 = plt.subplots(figsize = (20,9))  
color = 'tab:blue'

ind_m = np.arange(len(set(df.mois))) #indice mensuel


ax1.set_xlabel('mois')  
ax1.set_ylabel('moyenne du trafic vélo quotidienne (compteur)', color = color)  
ax1.plot(ind_m, df.mean_velo_compteur.groupby(df["mois"]).mean()*4,  color = color, linewidth=3, marker = 'o', markersize = 10 )  #line mensuelle

ax1.tick_params(axis ='y', labelcolor = color)  
ax1.grid(axis = "x", linestyle='dotted')
plt.xticks( [0,1,2,3,4,5,6,7,8,9,10,11],['Jan', 'Fev', 'Mar', 'Avr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] ) #axe mensuel

ax2 = ax1.twinx()  

color = 'tab:green'
ax2.set_ylabel('part du trafic vélo en % de trafic (compteur)', color = color)  
ax2.plot(ind_m, df["part_velo_compteur"].groupby(df["mois"]).mean(),  color = color, linewidth=3, marker = 'o', markersize = 10 ) #line mensuelle
ax2.tick_params(axis ='y', labelcolor = color)  

#On reformate les étiquettes de l'axe des ordonnées en pourcentage
ax2.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))

plt.title('Comparaison de la moyenne de trafic vélo horaire mensuelle avec la part vélo mensuelle dans le trafic', fontweight ="bold")  
  
plt.show();

# On crée ici un graphique comparant au quotidien l'expression de la moyenne quotidienne du trafic vélo et de la moyenne glissante sur 30 jours
fig, ax1 = plt.subplots(figsize = (20,9))  
color = 'tab:blue'


ax1.set_xlabel('mois')  
ax1.set_ylabel('moyenne du trafic vélo quotidienne (compteur)', color = color)  
ax1.plot(df.day, df.mean_velo_compteur,  color = color, linewidth=3 ) #line quotidienne

ax1.tick_params(axis ='y', labelcolor = color)  
ax1.grid(axis = "x", linestyle='dotted')
plt.xticks( [1,30,60,90,120,150,180,210,240,270,300,330],['Jan', 'Fev', 'Mar', 'Avr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] ) #axe quotidien

ax2 = ax1.twinx()  

color = 'tab:green'
ax2.set_ylabel('moyenne glissante sur 30 jours du trafic vélo (compteur)', color = color)  
ax2.plot(df.day, df["glissmean_velo_compteur"],  color = color, linewidth=3 ) #line quotidienne

ax2.tick_params(axis ='y', labelcolor = color)  

plt.title('Comparaison de la moyenne de trafic vélo horaire mensuelle avec la moyenne glissante de trafic vélo sur 30 jours', fontweight ="bold")  
  
plt.show();

# On crée ici un graphique comparant au quotidien l'expression de la moyenne quotidienne du trafic vélo et de la moyenne des trends google sur la thématique du vélo
fig, ax1 = plt.subplots(figsize = (20,9))  
color = 'tab:blue'


ax1.set_xlabel('mois')  
ax1.set_ylabel('moyenne du trafic vélo quotidienne (compteur)', color = color)  
ax1.plot(df.day, df.mean_velo_compteur,  color = color, linewidth=3 ) #line quotidienne

ax1.tick_params(axis ='y', labelcolor = color)  
ax1.grid(axis = "x", linestyle='dotted')
plt.xticks( [1,30,60,90,120,150,180,210,240,270,300,330],['Jan', 'Fev', 'Mar', 'Avr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] ) #axe quotidien

ax2 = ax1.twinx()  

color = 'tab:green'
ax2.set_ylabel('moyenne glissante sur 90 jours des trends google autour du vélo', color = color)  
ax2.plot(df.day, df["trend_glissmean_90"],  color = color, linewidth=3 ) #line quotidienne

ax2.tick_params(axis ='y', labelcolor = color)  

plt.title('Comparaison de la moyenne de trafic vélo horaire mensuelle avec la moyenne glissante sur 90 jours des trends google autour du vélo', fontweight ="bold")  
  
plt.show();

"""## Analyse statistique via le test de corrélation de Pearson

"""

# Import des packages nécessaires à l'analyse statistique
import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.stats.api import anova_lm

# Création de la table d'analyse statistique pour le données météorologiques
meteo_lm = ols('mean_velo_compteur ~ opinion + max_temperature_c + min_temperature_c + windspeed_max_kmh + \
  temperature_morning_c + temperature_noon_c + temperature_evening_c + precip_total_day_mm + humidity_max_percent + \
  visibility_avg_km + pressure_max_mb + cloudcover_avg_percent + heatindex_max_c + dewpoint_max_c + \
  windtemp_max_c + weather_code_morning + weather_code_noon + weather_code_evening + total_snow_mm + uv_index + sunhour + temperature_night_c' , data = df).fit()

table = anova_lm(meteo_lm)
display(table)

# Création de la table d'analyse statistique pour le données de trafic
trafic_lm = ols('mean_velo_compteur ~ mean_trafic_compteur + mean_total_valid + glissmean_velo_compteur' , data = df).fit()
table = anova_lm(trafic_lm)

#On affiche la table et les résultats
display(table)

# Création de la table d'analyse statistique pour le données calendaires
trafic_lm = ols('mean_velo_compteur ~ mois + weekday + typejour' , data = df).fit()
table = anova_lm(trafic_lm)

#On affiche la table et les résultats
display(table)

"""# Visualisation des données

## Visualisation des relations entre la variable cible et le variables explicatives

Afin de visualiser la corrélation entre la variable cible et les variables explicatives, nous décidons de découper ces variables en 3 : météo, trafic et variables calendaires et de représenter des heatmaps.
"""

#Instanciation d'une variable regroupant l'ensemble des features météo et la variable cible
meteo_df = df[['mean_velo_compteur', 'max_temperature_c',
               'min_temperature_c', 'windspeed_max_kmh', 'temperature_morning_c',
               'temperature_noon_c', 'temperature_evening_c', 'temperature_night_c', 'precip_total_day_mm',
               'humidity_max_percent', 'visibility_avg_km', 'pressure_max_mb', 'dewpoint_max_c',
               'cloudcover_avg_percent', 'heatindex_max_c', 'total_snow_mm',
               'uv_index', 'sunhour', 'opinion']].copy()

#Visualisation des corrélations entre la variable cible et les features météo via une heatmap
plt.figure(figsize=(15,10))
sns.heatmap(meteo_df.corr(), annot= True, cmap = "magma")

#On ajoute un titre au graphique
plt.title('Matrice de corrélation des variables météorologiques sur la variable cible');

"""On analyse ensuite les corrélations entre entre la variable cible et les données de trafic. Pour cela, nous crééons le dataframe "trafic_df"."""

##Instanciation d'une variable regroupant l'ensemble des features de trafic et la variable cible
trafic_df = df[['mean_velo_compteur', 'mean_trafic_compteur','mean_total_valid', 'glissmean_velo_compteur']].copy()

#Visualisation des corrélations entre la variable cible et les features météo via une heatmap
plt.figure(figsize=(15,10))
sns.heatmap(trafic_df.corr(), annot= True, cmap = "magma")

#On ajoute un titre au graphique
plt.title('Matrice de corrélation des variables de trafic sur la variable cible');

"""Pour finir, on analyse les corrélations entre la variable cible et les variables calendaires. Pour cela, nous crééons le dataframe "calend_df"
"""

##Instanciation d'une variable regroupant l'ensemble des features calendaires et la variable cible et transformation des variables 'object' en variables en échelle numériques
calend_df = df[['mean_velo_compteur', 'numsem', 'weekday', 'mois', 'typejour']]
calend_df['weekday'] = calend_df['weekday'].replace(dict(zip(df.weekday.unique(), [1,2,3,4,5,6,7])))
calend_df['typejour'] = calend_df['typejour'].replace(dict(zip(df.typejour.unique(), [1,4,3,2])))

#Visualisation des corrélations entre la variable cible et les features calendaires via une heatmap
plt.figure(figsize=(15,10))
sns.heatmap(calend_df.corr(), annot= True, cmap = "magma")

#On ajoute un titre au graphique
plt.title('Matrice de corrélation des variables calendaires sur la variable cible');

"""## Répartition moyenne de l'usage vélo en fonction des mois et des jours de la semaine

Pour comprendre la périodicité de l'utilisation du vélo au cours de l'année et au cours de la semaine, il est intéressant d'observer le nombre de déplacement sur ces périodes.
"""

#On crée une variable 'weekday_nom', nous permettant d'obtenir le jour de la semaine (en chiffre)
weeks = {'Monday': 0, 'Tuesday' : 1, 'Wednesday' : 2, 'Thursday' : 3, 'Friday' : 4, 'Saturday' : 5, 'Sunday' : 6} 
df['weekday_num'] = df['weekday'].map(weeks) 

#On fait la somme du nombre de comptage vélo par jour de la semaine et on l'ordonne.
count_velo_weekday = df.groupby('weekday_num')['mean_velo_compteur'].mean()*4

#On crée un graphique en barre pour observer les résultats
plt.figure(figsize = (10,5))
plt.bar(count_velo_weekday.index, count_velo_weekday.values, color='teal')

#On ajoute les légendes
plt.xticks([0, 1, 2, 3, 4, 5, 6,], ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche'])
plt.ylabel("moyenne horaire du trafic vélo par jour (données de compteur)")
plt.xlabel("Jour de la semaine");

#On crée un graphique en barre représentant le nombre moyen de comptage vélo par type de jour et on l'ordonne.
plt.figure(figsize = (9,5))
mean_trafic_velo_typejour = df.groupby('typejour')['mean_velo_compteur'].mean()*4
plt.bar(mean_trafic_velo_typejour.index, mean_trafic_velo_typejour.values, color='teal')
plt.ylim(0)

#On ajoute les légendes
plt.ylabel("Moyenne horaire du trafic vélo (données de compteur)")
plt.xlabel("Type Jour")
plt.title("Moyenne horaire du trafic vélo par type de jour");

#On crée un graphique en barre représentant le nombre de comptage vélo par mois et on l'ordonne.
plt.figure(figsize = (9,9))
trafic_mois_velo = df.groupby('mois')['sum_velo_compteur'].sum()
plt.bar(trafic_mois_velo.index, trafic_mois_velo.values, color='teal')
plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], ['Janvier', 'Février', 'Mars', 'Avril', 'Mai', 'Juin', 'Juillet', 'Août', 'Septembre', 'Octobre', 'Novembre', 'Décembre'], rotation = 60)
plt.ylim(0)

#On ajoute les légendes
plt.ylabel("Somme du nombre de comptage de vélo (en millions")
plt.xlabel("Mois")
plt.title("Evolution du trafic de vélo à Paris par mois en 2021");

"""# Modélisation

### Instanciation des échantillons
"""

#On charge les packages nécessaires
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_validate
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import Ridge, LassoCV, LinearRegression
from sklearn.model_selection import \
    KFold, RepeatedKFold, GridSearchCV, \
    cross_validate, train_test_split

cv = KFold(n_splits=5, shuffle=True, random_state=123)

# On conserve les variables explicatives nécessaires à notre analyse :
col_total_compteur = ["mean_trafic_compteur", 'max_temperature_c',  "mean_total_valid", 
                      'windspeed_max_kmh', 'temperature_morning_c', 'min_temperature_c',
                     'temperature_noon_c', 'temperature_evening_c', 'precip_total_day_mm',
                      'humidity_max_percent', 'visibility_avg_km', 'pressure_max_mb',
                      'cloudcover_avg_percent', 'heatindex_max_c', 'dewpoint_max_c',
                      'windtemp_max_c', 'total_snow_mm', 'uv_index', 'sunhour',
                      'temperature_night_c', "typejour", "opinion", "glissmean_velo_compteur", "nom_mois"]

# On sépare notre dataframe entre notre variable cible et nos variables explicatives:
feats = df[col_total_compteur]
target = df["mean_velo_compteur"]

# On dichotomise les variables catégorielles :
feats = feats.join(pd.get_dummies(feats["typejour"], prefix= "jour"))
del(feats["typejour"])
feats = feats.join(pd.get_dummies(feats["opinion"], prefix= "o"))
del(feats["opinion"])
feats = feats.join(pd.get_dummies(feats["nom_mois"], prefix= "mois"))
del(feats["nom_mois"])

# On sépare notre dataframe en échantillons de test et d'entraînement :
X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=(100/365), shuffle = True, random_state = 123)

# On standardise les variables :
scaler = preprocessing.StandardScaler().fit(X_train)

X_train = scaler.transform(X_train)
X_train = pd.DataFrame(X_train, index = range(0,265))
feats_col = feats.columns
scaled_col = X_train.columns
dict_col = dict(zip(scaled_col, feats_col))
X_train.rename(columns = dict_col, inplace = True)

X_test = scaler.transform(X_test)
X_test = pd.DataFrame(X_test, index = range(0,100))
X_test.rename(columns = dict_col, inplace = True)

# On définit ici une fonction qui pour un modèle donné l'entraînement sur les données X_train et présente ses principaux indicateurs de performances

def result_model (model, model_name) :
  
  #on  entraîne le modèle sur le dataset de train :
  model.fit(X_train, y_train)

  #on crée deux array intégrant les résultats des prédictions sur les échantillons de train et de test :
  pred_train = model.predict(X_train)
  pred_test = model.predict(X_test)

  #On affiche les RMSE et score de R2 pour les deux échantillons :
  print("Modèle "+ model_name + " - rmse (train set):", np.sqrt(mean_squared_error(pred_train,y_train)))
  print('Modèle '+ model_name + ' - rmse (test set):', np.sqrt(mean_squared_error(pred_test, y_test)))
  print('\nModèle '+ model_name + ' - score R² (train set): ' , model.score(X_train, y_train))
  print('Modèle '+ model_name + ' - score R² (test set): ' , model.score(X_test, y_test))

  #On observe l'alignement des prédictions sur la variable cible via un scatterplot
  plt.title("Alignement des prédictions avec la variable cible")
  plt.scatter(pred_test, y_test)
  plt.plot((y_test.min(), y_test.max()), (y_test.min(), y_test.max()))
  plt.show()
  ;

  # Représentation graphique des valeurs résiduelles sur l'échantillon de train
  residus_train = pred_train - y_train

  plt.scatter(y_train, residus_train, color='#980a10', s=15)
  plt.ylim(5,-5)
  plt.plot((y_train.min(), y_train.max()), (0, 0), lw=3, color='#0a5798')
  plt.title("Residual errors - train")
  plt.show()
  ;

  # Représentation graphique des valeurs résiduelles sur l'échantillon de test
  residus_test = pred_test - y_test

  plt.scatter(y_test, residus_test, color='#980a10', s=15)
  plt.ylim(5,-5)
  plt.plot((y_test.min(), y_test.max()), (0, 0), lw=3, color='#0a5798')
  plt.title("Residual errors - test")
  plt.show()
  ;

"""## Modélisation par Régression linéaire

### Régression linéaire multiple
"""

#On instance notre modèle et on mesure ses performances
from sklearn.linear_model import LinearRegression
lr = LinearRegression()

result_model(lr, 'LinearRegression')

"""### Modèle Ridge"""

#On instance notre modèle et on mesure ses performances
from sklearn.linear_model import Ridge
ridge_reg = Ridge(alpha = 2.020211818181818, solver = 'lsqr')

result_model(ridge_reg, 'Ridge')

"""### Modèle Lasso"""

#On instance notre modèle et on mesure ses performances
from sklearn.linear_model import Lasso
model_lasso = Lasso(alpha = 0.000009, max_iter = 251, selection = "random" )

result_model(model_lasso, 'Lasso')

"""### Modèle Elastic Net

Il s'agit d'un mélange de régression Ridge et Lasso qui fait ressortir un effet de regroupement lorsque des prédicteurs fortement corrélés s'approchent ou s'éloignent du modèle de manière combinée.

Il est recommandé d'utiliser ce modèle lorsque le nombre de prédicteurs est très supérieur au nombre d'observations.
"""

#On instance notre modèle et on mesure ses performances
from sklearn.linear_model import ElasticNetCV 
model_enCV = ElasticNetCV(l1_ratio = 0.5555599999999999, alphas = (0.001, 0.01, 0.02, 0.025, 0.05, 0.1, 0.25, 0.5, 0.8, 1.0), n_alphas=6, eps = 0.00001, fit_intercept = True)

result_model(model_enCV, 'ElasticNet')

"""## Modélisation par régression non linéaire

### XGBRegressor
"""

#On instance notre modèle et on mesure ses performances
from sklearn import datasets
from sklearn import metrics
from sklearn.model_selection import train_test_split
plt.style.use("ggplot")
import xgboost as xgb

xgbR = xgb.XGBRegressor(objective ='reg:squarederror',booster = 'gbtree', reg_lambda = 0.16778523489932887, 
                       reg_alpha = 0.35570469798657717, max_depth = 5, max_leaves = 0, gamma = 0.4809045226130653,
                        max_delta_step = 7 , 
                        min_child_weight = 11 , 
                        process_type = 'default',
                        subsample = 0.4977386934673367,
                       learning_rate = 0.1357718120805369, base_score = 0.48743718592964824)


result_model(xgbR, 'XGB Regressor')

"""### Decision Tree Regression

"""

#On instance notre modèle et on mesure ses performances

from sklearn.tree import DecisionTreeRegressor

tree=DecisionTreeRegressor(criterion = "friedman_mse", max_depth= 38, splitter = "random", random_state = 380)

result_model(tree, 'Decision Tree')

"""### Random Forest Regression"""

#On instance notre modèle et on mesure ses performances

from sklearn.ensemble import RandomForestRegressor

forest = RandomForestRegressor(n_estimators=23,
                             max_depth=10,
                             criterion='squared_error',random_state = 780
                            )

result_model(forest, 'Random Forest')

"""### Support Vector Regressor (SVR)"""

#On instance notre modèle et on mesure ses performances

from sklearn import svm
from sklearn.svm import SVR

svr = svm.SVR(kernel='rbf', gamma =0.0008299277376320178, C = 556.7593107281823, epsilon = 0.09319732441471572, tol = 0.09031070234113713)

result_model(svr, 'SVR')

"""### Nu Support Vector Regression (NuSVR)"""

#On instance notre modèle et on mesure ses performances

from sklearn.svm import NuSVR

Nusvr = svm.NuSVR(kernel='rbf', gamma =0.0007372372372372372, nu = 0.9897897897897898, C = 266, tol = 0.45)

result_model(Nusvr, 'NuSVR')

"""### Gaussian Process Regression (GPR)"""

#On instance notre modèle et on mesure ses performances
from sklearn.gaussian_process.kernels import (RBF, Matern, RationalQuadratic,ExpSineSquared, DotProduct,ConstantKernel)
from sklearn.gaussian_process.kernels import ExpSineSquared
from sklearn.gaussian_process import GaussianProcessRegressor

kernel_1 =1.0 * RBF( length_scale=1.0 , length_scale_bounds=(0.1, 10.0))

gpr = GaussianProcessRegressor(kernel = kernel_1, alpha=0.6)

result_model(gpr, 'Gaussian Process Regressor')

"""### Random Sample Consensus (RANSAC) Regression"""

#On instance notre modèle et on mesure ses performances
from sklearn.linear_model import RANSACRegressor

ransac = RANSACRegressor(LinearRegression(),
		max_trials=22, 		# Number of Iterations
		min_samples=32, 		# Minimum size of the sample
		loss='absolute_error', 	# Metrics for loss
		residual_threshold=2, 	# Threshold
		random_state = 399
		)

result_model(ransac, 'RANSAC')

"""### K Nearest Neighbors (KNN) Regressor

"""

#On instance notre modèle et on mesure ses performances

from sklearn import neighbors
knn = neighbors.KNeighborsRegressor(n_neighbors = 8, metric = "cosine", weights= 'distance' )

result_model(knn, 'KNN Regressor')

"""### BayesianRidge

"""

#On instance notre modèle et on mesure ses performances
from sklearn.linear_model import BayesianRidge

bayesian = BayesianRidge( n_iter=1, tol=0.00001, alpha_init = 1.35, lambda_init = 0.99665, alpha_1=10000, alpha_2=1e-100, 
                         lambda_1=1e-100, lambda_2=10000)


result_model(bayesian, 'Bayesian ridge')

"""### Multi-Layer Perceptron (MLP) Regression



"""

#On instance notre modèle et on mesure ses performances

from sklearn.neural_network import MLPRegressor

mlp_lbfgs = MLPRegressor(activation = 'logistic',
 learning_rate= 'invscaling',
 solver= 'lbfgs', alpha = 0.8499874371859297, batch_size = 1, tol =0, hidden_layer_sizes = (60,), random_state = 138)

result_model(mlp_lbfgs, 'MLP LBFGS')

# On instance notre modèle et on mesure ses performances
from sklearn.neural_network import MLPRegressor

mlp_sgd = MLPRegressor(activation = 'relu',
 learning_rate= 'adaptive',
 solver= 'sgd',  alpha = 0.01731438127090301, batch_size = 70, tol = 0, hidden_layer_sizes = (60,),learning_rate_init = 0.018364548494983278, momentum = 0, random_state = 1133)

result_model(mlp_sgd, 'MLP SGD')

"""### Kernel Ridge Regression (KRR) """

# On instance notre modèle et on mesure ses performances
from sklearn.kernel_ridge import KernelRidge
krr_model = KernelRidge(alpha=0.6515635451505017, kernel = 'polynomial', gamma = 0.05809045226130653, degree = 3,  coef0 = 0.7477386934673367).fit(X_train, y_train)


result_model(krr_model, 'Kernel Ridge Regression')

"""#Tableau de combinaisons de modèles"""

import itertools
import statistics
from sklearn.metrics import r2_score

# On instancie qui reprennent les prédictions sur les échantillons de test et de train plus les noms de chaque modèles : 


list_pred_model_train = [gpr.predict(X_train), tree.predict(X_train), forest.predict(X_train), svr.predict(X_train),
                           ransac.predict(X_train), lr.predict(X_train), ridge_reg.predict(X_train),
                           model_lasso.predict(X_train), model_enCV.predict(X_train), knn.predict(X_train), Nusvr.predict(X_train), bayesian.predict(X_train), mlp_lbfgs.predict(X_train),
                         mlp_sgd.predict(X_train), xgbR.predict(X_train), krr_model.predict(X_train)]

list_pred_model_test = [gpr.predict(X_test), tree.predict(X_test), forest.predict(X_test), svr.predict(X_test),
                           ransac.predict(X_test), lr.predict(X_test), ridge_reg.predict(X_test),
                           model_lasso.predict(X_test), model_enCV.predict(X_test), knn.predict(X_test), Nusvr.predict(X_test), bayesian.predict(X_test), mlp_lbfgs.predict(X_test),
                        mlp_sgd.predict(X_test), xgbR.predict(X_test), krr_model.predict(X_test)]

list_model_name = ['GPR', 'tree', 'forest', 'svr', 'ransac', 'linear', 
                      'ridge', 'lasso', 'ElasticNEt', 'KNN', 'NuSVR', 'Bayesian', 'MLP_LBFGS', 'MLP_SGD', 'XBG', 'KRR']

# On crée une boucle 'for' qui évalue toutes les combinaisons de modèles sur la moyenne des résidus et sur l'écart type :

# on fixe un nombre de combinaisons (itr) comrpises entre 1 (modèle unique) et une combinaison de tous les modèles
itr = range(1,len(list_model_name)+1)
itr = [1,2,3]
result = pd.DataFrame([])
for y in itr :

  # On instancie une colonne qui va recevoir la moyenne des prédictions
  mean_model_train = []
  df_pred_train = pd.DataFrame(itertools.combinations(list_pred_model_train,y), index = itertools.combinations(list_model_name,y))
  
  mean_model_test = []
  df_pred_test = pd.DataFrame(itertools.combinations(list_pred_model_test,y), index = itertools.combinations(list_model_name,y))

  for r in list(range(0,len(df_pred_train))) :
    mean_model_train.append(list(range(0,265)))
  df_pred_train["pred"] = mean_model_train

  for r in list(range(0,len(df_pred_test))) :
    mean_model_test.append(list(range(0,100)))
  df_pred_test["pred"] = mean_model_test

  # On crée une boucle qui va calculer la moyenne pour chaque target de la prédiction de l'ensemble des combinaisons de modèles :
  for row in list(range(0,265)) :
    for combo in list(range(0,len(df_pred_train))) :
      list_mean_train = []
      for x in list(range(0,y)) :
        list_mean_train.append(df_pred_train[x][combo][row])
      df_pred_train["pred"][combo][row] = statistics.median(list_mean_train)
  
  # On crée une boucle qui va calculer le score de R2 pour chaque combinaisons de modèles :
  list_train_score = []
  list_train_rmse = []
  for combo2 in list(range(0,len(df_pred_train))) :
    list_train_score.append(r2_score(y_train, df_pred_train["pred"][combo2]))
    list_train_rmse.append(np.sqrt(mean_squared_error(df_pred_train["pred"][combo2], y_train)))
  df_pred_train["train_score"] = list_train_score
  df_pred_train["train_rmse"] = list_train_rmse

 # On crée une boucle qui va calculer la moyenne pour chaque target de la prédiction de l'ensemble des combinaisons de modèles :
  for row in list(range(0,100)) :
    for combo in list(range(0,len(df_pred_test))) :
      list_mean_test = []
      for x in list(range(0,y)) :
        list_mean_test.append(df_pred_test[x][combo][row])
      df_pred_test["pred"][combo][row] = statistics.median(list_mean_test)
  
  # On crée une boucle qui va calculer le score de R2 pour chaque combinaisons de modèles :
  list_test_score = []
  list_test_rmse = []
  for combo2 in list(range(0,len(df_pred_test))) :
    list_test_score.append(r2_score(y_test, df_pred_test["pred"][combo2]))
    list_test_rmse.append(np.sqrt(mean_squared_error(df_pred_test["pred"][combo2], y_test)))
  df_pred_test["test_score"] = list_test_score
  df_pred_test["test_rmse"] = list_test_rmse

  # On crée un DataFrame temporaire qui va accueillir les deux metrics et se fusionner avec result :
  df_combi = pd.DataFrame([])
  df_combi["train score"] = df_pred_train["train_score"]
  df_combi["test score"] = df_pred_test["test_score"]
  df_combi["train_rmse"] = df_pred_train["train_rmse"]
  df_combi["test_rmse"] = df_pred_test["test_rmse"]

  frames = (result, df_combi)
  result = pd.concat(frames, join = "outer")


# On crée une variable qui compte le nombre de combinaisons totales testées :
result = result.reset_index()
result['nb_combo'] = result['index'].apply(lambda x : len(x))

# Vue des 50 combinaisons de modèles les plus performantes sur le test score
result.sort_values(by = "test score", key = abs, ascending = False).head(50)

# Tableau récap des résultats par modèles uniques

result[result['nb_combo'] == 1].sort_values(by = "test score", key = abs, ascending = False)

"""# Visualisation des performances des modèles"""

# Instanciation de trois listes (prédictions sur le X_test par modèle, nom des modèles testés, et score des modèles sur le X_test)

list_pred_model_test = [Nusvr.predict(X_test), 
                        krr_model.predict(X_test),
                        mlp_sgd.predict(X_test),
                        svr.predict(X_test),
                        mlp_lbfgs.predict(X_test),                        
                        gpr.predict(X_test),
                        xgbR.predict(X_test),
                        ransac.predict(X_test),
                        forest.predict(X_test),
                        lr.predict(X_test),
                        model_enCV.predict(X_test),
                        model_lasso.predict(X_test),
                        ridge_reg.predict(X_test),
                        bayesian.predict(X_test),
                        knn.predict(X_test),
                        tree.predict(X_test)]

list_model_name = ['NuSVR',
                   'KRR',
                   'MLP_SGD',
                   'svr',
                   'MLP_LBFGS',
                   'GPR',
                   'XBG',
                   'ransac',
                   'forest',
                   'linear', 
                   'ElasticNEt',
                   'lasso',
                   'ridge',
                   'Bayesian',
                   'KNN',                   
                   'tree']

list_R2test = [Nusvr.score(X_test, y_test), 
                        krr_model.score(X_test, y_test),
                        mlp_sgd.score(X_test, y_test),
                        svr.score(X_test, y_test),
                        mlp_lbfgs.score(X_test, y_test),                        
                        gpr.score(X_test, y_test),
                        xgbR.score(X_test, y_test),
                        ransac.score(X_test, y_test),
                        forest.score(X_test, y_test),
                        lr.score(X_test, y_test),
                        model_enCV.score(X_test, y_test),
                        model_lasso.score(X_test, y_test),
                        ridge_reg.score(X_test, y_test),
                        bayesian.score(X_test, y_test),
                        knn.score(X_test, y_test),
                        tree.score(X_test,y_test)]



# On crée une boucle pour afficher sous forme graphique les performances de chacun des modèles
# 4 subplot de 4 colonnes s'enchaînent avec à chaque fois :
    # le rapport entre les prédictions et les valeurs réelles
    # deux lignes qui bleues délimitent une marge d'erreur "acceptable" de + ou - 1 par rapport à la moyenne de trafic (1/4 d'h) réelle
    # le rappel du score de R2 sur l'échantillon test

sp = 1
x = 0
seq = range(4)
for s in seq :
    plt.figure(figsize=(30,7))
    a = sp + 140
    
    plt.subplot(a)
    plt.scatter(y_test, list_pred_model_test[x],c = abs(y_test - list_pred_model_test[x]) >= 1, cmap = 'coolwarm')
    plt.plot(y_test,y_test +1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.plot(y_test,y_test - 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.title(list_model_name[x] + " ( R2 = " + str(list_R2test[x]) + ")")
    plt.xlabel("valeur réelle")
    plt.ylabel("valeur prédite")
    
    plt.subplot(a+1)
    plt.scatter(y_test, list_pred_model_test[x+1],c = abs(y_test - list_pred_model_test[x+1]) >= 1, cmap = 'coolwarm')
    plt.plot(y_test,y_test + 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.plot(y_test,y_test - 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.title(list_model_name[x+1] + " ( R2 = " + str(list_R2test[x+1]) + ")")
    plt.xlabel("valeur réelle")
    plt.ylabel("valeur prédite")
    
    plt.subplot(a+2)
    plt.scatter(y_test, list_pred_model_test[x+2],c = abs(y_test - list_pred_model_test[x+2]) >= 1, cmap = 'coolwarm')
    plt.plot(y_test,y_test + 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.plot(y_test,y_test - 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.title(list_model_name[x+2] + " ( R2 = " + str(list_R2test[x+2]) + ")")
    plt.xlabel("valeur réelle")
    plt.ylabel("valeur prédite")
    
    plt.subplot(a+3)
    plt.scatter(y_test, list_pred_model_test[x+3],c = abs(y_test - list_pred_model_test[x+3]) >= 1, cmap = 'coolwarm')
    plt.plot(y_test,y_test + 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.plot(y_test,y_test - 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.title(list_model_name[x+3] + " ( R2 = " + str(list_R2test[x+3]) + ")")
    plt.xlabel("valeur réelle")
    plt.ylabel("valeur prédite")   
    
    plt.show()
    
    x = x+4
    ;

"""# Réduction de dimension

## SKBest
"""

#On importe SelectKBest et f_regression
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression

#On instancie deux listes : une qui reprend cumule l'ensemble des modèles testés, l'autre leurs noms en format 'str' :

liste_model = [gpr, tree, forest, svr,
                           ransac, lr, ridge_reg,
                           model_lasso, model_enCV, knn, Nusvr, bayesian, mlp_lbfgs,
                        mlp_sgd, xgbR, krr_model]
                        
list_model_name = ['GPR', 'tree', 'forest', 'svr', 'ransac', 'linear', 
                      'ridge', 'lasso', 'ElasticNEt', 'KNN', 'NuSVR', 'Bayesian', 'MLP_LBFGS', 'MLP_SGD', 'XBG', 'KRR']

# On crée ici une boucle for qui permet pour chaque modèle ainsi crée de tester les combinaisons de variables les plus optimales via la méthode du SelectKbest :


# On instancie d'abord une boucle for qui va répéter les opérations suivantes pour tous les modèles testés :
x = 0
for model in liste_model :
  # On instancie d'abord deux listes vides prêtes à recevoir les résultats du test pour chaque combinaisons de variables
  train_score_per_nbvar = []
  test_score_per_nbvar = []
  # on définit la range du nombre de variable à tester comme le nombre de variable total présent dans X_train
  range_sk = range(1,len(X_train.columns)+1)
 
  # On ensuite pour un modèle donné une boucle de SelectKbest qui va mesurer ses performances en fonction du nombre de variables possibles :
  for nbvar in range_sk :
    
    # on instancie le SelectKbest et on l'entraîne sur les données d'entraînement
    sk = SelectKBest(f_regression, k= nbvar)
    sk.fit(X=X_train, y=y_train)
    
    # on transforme ensuite nos datasets de test et de train en fonction du nombre de variables sélectionnées
    sk_train = sk.transform(X_train)
    sk_test = sk.transform(X_test)

    # on fit le modèle sur ces nouveaux datasets et on écrit dans les listes précédentes ses résultats (R2 Train et Test)
    model.fit(sk_train, y_train)
    train_score_per_nbvar.append(model.score(sk_train, y_train))
    test_score_per_nbvar.append(model.score(sk_test, y_test))
  
  # On instancie un dataframe avec les résultats des deux listes puis on isole l'index du meilleur ["test_score"]
  score_per_nbvar = pd.DataFrame(zip(train_score_per_nbvar,test_score_per_nbvar), columns = ["train_score","test_score"], index = range(1,len(X_train.columns)+1))
  test_max = score_per_nbvar[score_per_nbvar["test_score"] == score_per_nbvar["test_score"].max()].index[0]
  
  # pour finir pour chaque modèle testé on crée un graph représentant la variation des scores de train et test en fonction du nombre de variables sélectionnées
  # et dans lequel on affiche un axe vertical sur la position correspondant au meilleur résultat de test score
  plt.figure(figsize = (20,5))
  plt.plot(range_sk,train_score_per_nbvar, color = "red", label = "train_score" )
  plt.plot(range_sk,test_score_per_nbvar, color = "green", label = "test_score" )
  plt.title( str(list_model_name[x]) + " : évolution du r2 train et test en fonction du nombre de variables sélectionnées")
  plt.ylabel("r2")
  plt.xlabel("Nombre de variables sélectionnées")
  plt.axvline(x=test_max, color = "green", label = "test score max pour r2 = " + str(test_max) ,linestyle='--')
  plt.legend()
  x = x + 1
  print(x)
  ;

sk = SelectKBest(f_regression, k= 23)
sk.fit(X=feats, y=target)

sk_train = sk.transform(X_train)
sk_test = sk.transform(X_test)

krr_model.fit(sk_train, y_train)

print("train score pour " + str(21) + " variables : " + str(krr_model.score(sk_train, y_train)))
print("test score pour " + str(21) + " variables : " + str(krr_model.score(sk_test, y_test)))
variables_select = pd.DataFrame(feats.columns[sk.get_support()], index = range(0,23), columns = ["var_sel"])

X_train_opt = X_train[feats.columns[sk.get_support()]]
X_test_opt = X_test[feats.columns[sk.get_support()]]

X_train_opt.info()

"""## Analyse des Composantes Principales (ACP)"""

from sklearn.decomposition import PCA


# On test d'abord une ACP sur l'ensemble des variables explicatives

# Instanciation de l'ACP et transformation des datasets X_train et X_test
pca = PCA(svd_solver = 'randomized')

Coord_train = pca.fit_transform(X_train)
Coord_test = pca.transform(X_test)

# Affichage des valeurs propres par facteurs
print('Les valeurs propres sont :', pca.explained_variance_)

# Représentation des valeurs propres dans un graphique
plt.plot(range(0, 42), pca.explained_variance_)
plt.xlabel('Nombre de facteurs')
plt.ylabel('Valeurs propres');
plt.show()

# Affichage du ratio de variance expliquée par facteur
print('Les ratio sont :', pca.explained_variance_ratio_)

# Représentation grapgique de la somme cumulative de la variance expliquée
plt.plot(np.arange(1, 43), np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Factor number')
plt.ylabel('Cumsum');
plt.show()

# Instanciation de deux listes des ratios d'explication de la variance, l'une contenant les premières dimensions les plus explicatives, la seconde le reste des dimensions
L1 = list(pca.explained_variance_ratio_[0:18])
L1.append(sum(pca.explained_variance_ratio_[18:43]))

# Création d'un graph représentant la part d'explication de la variance des principales dimensions + la somme des autres
plt.pie(L1, labels=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18','Autres'], 
        autopct='%1.0f%%');

# Instanciation des dataframe de Train et Test transformés par l'ACP sur les principales dimensions
X_train_ACP_1 = pd.DataFrame(Coord_train[:,:18], index = range(0,265))
X_test_ACP_1 = pd.DataFrame(Coord_test[:,:18], index = range(0,100))

# On test ensuite l'ACP uniquement sur les variables météos

# On isole en premier lieu les variables météos à injecter au modèle
var_météo = ['max_temperature_c','min_temperature_c', 'windspeed_max_kmh',
       'temperature_morning_c', 'temperature_noon_c', 'temperature_evening_c',
       'precip_total_day_mm', 'humidity_max_percent', 'visibility_avg_km',
       'pressure_max_mb', 'cloudcover_avg_percent', 'heatindex_max_c',
       'dewpoint_max_c', 'windtemp_max_c', 'total_snow_mm', 'uv_index',
       'sunhour', 'temperature_night_c', 
       'o_météo correcte',
       'o_météo défavorable', 'o_météo favorable', 'o_météo idéale',
       'o_météo très défavorable']

X_météo_train = X_train[var_météo]
X_météo_test = X_test[var_météo]

# Instanciation de l'ACP et transformation des datasets X_train et X_test
    
pca_m = PCA()

Coord_météo_train = pca_m.fit_transform(X_météo_train)
Coord_météo_test = pca_m.transform(X_météo_test)

# Affichage des valeurs propres par facteurs
print('Les valeurs propres sont :', pca_m.explained_variance_)

# Représentation des valeurs propres dans un graphique
plt.plot(range(0, 23), pca_m.explained_variance_)
plt.xlabel('Nombre de facteurs')
plt.ylabel('Valeurs propres');
plt.show()

# Affichage du ratio de variance expliquée par facteur
print('Les ratio sont :', pca_m.explained_variance_ratio_)


# Représentation grapgique de la somme cumulative de la variance expliquée
plt.plot(np.arange(1, 24), np.cumsum(pca_m.explained_variance_ratio_))
plt.xlabel('Factor number')
plt.ylabel('Cumsum');
plt.show()

# Instanciation de deux listes des ratios d'explication de la variance, l'une contenant les premières dimensions les plus explicatives, la seconde le reste des dimensions
L1 = list(pca_m.explained_variance_ratio_[0:13])
L1.append(sum(pca_m.explained_variance_ratio_[13:31]))

# Création d'un graph représentant la part d'explication de la variance des principales dimensions + la somme des autres
plt.pie(L1, labels=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12','PC13','Autres'], 
        autopct='%1.0f%%');


# Création de liste des variables non météorologiques par différence avec la liste des variables météos
difference_1 = set(X_train_météo.columns).difference(set(feats.columns))
difference_2 = set(feats.columns).difference(set(X_train_météo.columns))
var_non_météo = list(difference_1.union(difference_2))

# Instanciation des dataframe de Train et Test transformés par l'ACP sur les principales dimensions
X_train_ACP2 = pd.concat((X_train[var_non_météo],(pd.DataFrame(Coord_météo_train[:,:13],index = range(0,265)))), join = 'inner', axis = 1)
X_test_ACP2 = pd.concat((X_test[var_non_météo],(pd.DataFrame(Coord_météo_test[:,:13],index = range(0,100)))), join = 'inner', axis = 1)

"""# Interprétabilité

## Interprétabilité du modèle de regression linéaire
"""

#Impression des coefficients
print(lr.coef_)

#Représentation des coefficients
pd.Series(lr.coef_, X_train.columns).sort_values(ascending=False).plot(kind='barh', figsize=(20,15));

cat_list = ['Déplacement', 'Météo', 'Déplacement', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Tendance',
                                      'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 
            'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire']

#On imprime le dataframe
result_LR = pd.DataFrame(zip(lr.coef_, X_train.columns), index = range(0,42), columns = ['Coef', 'Feature'])
result_LR["cat_var"] = cat_list
result_LR["coef_abs"] = result_LR.Coef.apply(lambda x :  abs(x))
result_LR["importance_percent"] = result_LR.coef_abs.apply(lambda x :  x/result_LR.coef_abs.sum())
result_LR

R = result_LR["importance_percent"].groupby(result_LR["cat_var"]).sum().sort_values(ascending = False)

plt.figure(figsize = (5,5))
plt.pie( R ,labels = R.index, autopct = '%1.0f%%', textprops={'fontsize': 14}, colors= ['tab:orange', 'tab:blue', 'tab:purple', 'tab:green'], startangle = 90, counterclock = False)
plt.title("Importance des features par catégories de variables",fontdict = {'fontsize' : 20}, pad = 50)
;

"""## Interprétabilité du modèle (NuSVR) à l'aide de SHAP"""

#On installe et importe la librairie Shap
! pip install shap
import shap

# On entraine l'explainer
explainer = shap.Explainer(Nusvr.predict, X_test)

# On calcule les valeurs de Shapley
shap_values = explainer(X_test)

#On crée un dataframe avec les valeurs de shap et on les ordonne
feature_names = shap_values.feature_names
shap_df = pd.DataFrame(shap_values.values, columns=feature_names)
vals = np.abs(shap_df.values).mean(0)
shap_importance = pd.DataFrame(list(zip(feature_names, vals)), columns=['col_name', 'feature_importance_vals'])
shap_importance.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True);

cat_list = ['Déplacement', 'Météo', 'Déplacement', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Tendance',
                                      'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Météo', 'Météo', 'Météo', 'Météo', 'Météo', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 
            'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire']

#On imprime le dataframe
result_NuSvr = shap_importance.sort_index()
result_NuSvr["cat_var"] = cat_list
result_NuSvr["importance_percent"] = result_NuSvr.feature_importance_vals.apply(lambda x :  x/result_NuSvr.feature_importance_vals.sum())

R = result_NuSvr["importance_percent"].groupby(result_NuSvr["cat_var"]).sum().sort_values(ascending = False)

plt.figure(figsize = (5,5))
plt.pie( R ,labels = R.index, autopct = '%1.0f%%', textprops={'fontsize': 14}, colors= ['tab:orange', 'tab:blue', 'tab:purple', 'tab:green'], startangle = 90, counterclock = False)
plt.title("Importance des features par catégories de variables",fontdict = {'fontsize' : 20}, pad = 50)
;

#On représente graphiquement l'importance des features dans le modèle via un barplot
shap.summary_plot(shap_values, X_test, plot_type="bar")

#Les features sont classées dans l'ordre croissant d'impact sur les prédictions.

#On représente les valeurs via un Beeswarm
shap.summary_plot(shap_values, max_display= 20)

#Sur le beeswarm, les features sont ordonnées selon leur impact sur les prédictions.
#Mais on peut aussi voir dans quelle mesure les features impactent positivement ou négativement le modèle.
#Chaque point sur le graph représente une observation. 
#L'axe horizontal représente la valeur SHAPE...
#Alors que la couleur de chaque point nous montre si une observation a une valeur supérieure ou inférieure, comparée aux autres observations.
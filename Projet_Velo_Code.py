# -*- coding: utf-8 -*-
"""Projet_Tricycle_Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fBS9Al1SPjW655VXGErHcNehsfYkvbRX

# **Code_Projet Tricycle**

# ‚ùå Ne pas √©x√©cuter  
# Pr√©processing et cr√©ation du dataset

La premi√®re chose que nous faisons est de cr√©er un dataset comprenant l'ensemble de nos sources de donn√©es (trafic routier et v√©lo, donn√©es m√©t√©o, transport en commun, ...) afin de pouvoir les analyser et impl√©menter dans nos mod√®les de Machine Learning.

Nous utiliserons une base 'jour' afin de pouvoir les compiler.

## Preprocessing Donn√©es de trafic routier - Compteurs permanents Paris 2021

Pour pouvoir compiler les donn√©es de trafic par compteur classique, nous avons compil√© les r√©sultats de dizaines de millions de mesures horaires sur l'ann√©e dispatch√©es en 58 fichiers correspondants √† peu pr√®s aux semaines de l'ann√©e.

Nous avons regroup√© les donn√©es par jour. Pour cela, nous avons impl√©ment√© une boucle pour traiter tous les fichiers √† la suite afin de tout compiler dans un seul dataframe. 

Cette boucle nous permet d‚Äôobtenir pour chaque jour de l‚Äôann√©e :
- La somme totale du trafic routier sur une journ√©e (somme des d√©bits horaires par capteurs et par jour)
- Le nombre total de mesures effectu√©es par tous les capteurs sur une journ√©e (une unit√© de compte = une heure pour un capteur)
- La moyenne du trafic par heure et par capteur (somme totale du trafic divis√© par le nombre d'unit√©s de compte sur une journ√©e).
"""

#On cr√©e une fonction qui nous permet de renommer les fichiers et de les ins√©rer dans une liste
liste_nomfichier = []
def nomfichier(a,b) :
    count = 1
    for x in range(0,59) :
        c = a+str(count)+b
        liste_nomfichier.append(c)
        count += 1

nomfichier("trafic_capteurs_2021_W (", ").txt")

#On cr√©e une nouvelle fonction qui va traiter les fichiers en boucle et remplir un DataFrame vide avec les donn√©es.
resultfinal = pd.DataFrame(columns=['day','q','count'])
def compilation(a) : 
        global resultfinal
        for x in a :
            # On lit chaque fichier de la liste
            df_temp = pd.read_table(r"C:\Users\admin\Desktop\Tricycle\Traffic 2021 par semaine/"+x, sep = ";")
            # On transforme la variable str qui contient la date au bon format
            df_temp["t_1h"] = pd.to_datetime(df_temp["t_1h"])
            # On cr√©e une variable day qui contient le num√©ro du jour de l'ann√©e (1 √† 365)
            df_temp["day"] = df_temp["t_1h"].apply(lambda x: x.strftime('%j'))
            # On d√©finit les fonctions √† appliquer puis on groupe en fonction du jour de l'ann√©e
            funct = {"q" : "sum", "day" : "count"}
            df_temp2 = df_temp[df_temp["t_1h"].dt.year == 2021].groupby("day").agg(funct)
            # On renomme les colonnes et on fixe un nouvel index (sinon deux variables "day")
            df_temp2 = df_temp2.rename(columns = {"day":"count"}) 
            df_temp2 = df_temp2.reset_index()
            # On regroupe les donn√©es dans le DataFrame final en sommant les variables pour un "day" identique
            resultfinal = pd.concat([resultfinal, df_temp2]).groupby(['day']).sum().reset_index()

#On compile l'ensemble des donn√©es.
compilation(liste_nomfichier)

"""## Preprocessing Donn√©es infrarouges (v√©los et autres modes de transport) Paris 2021

Nous nous attaquons ensuite aux donn√©es de trafic infrarouge

Pour les int√©grer √† notre dataframe, nous avons cr√©√© une variable "date" et une variable "day" au bon format.

Par la suite, afin de bien diff√©rencier les modes de transports motoris√©s et les mobilit√©s douces (v√©los, trotinettes), nous les avons regroup√©s sous deux variables ("Motoris√©" et "velo").
Nous avons √©galement calcul√© la somme et la moyenne des comptages .
Pour finir, nous avons extrait notre dataframe pour le fusionner avec les autres sur la variable 'day'
"""

#On lit le dataframe et on renomme les colonnes
df_infra = pd.read_table(r"C:\Users\admin\Desktop\Tricycle/comptage-multimodal-comptages.csv", sep = ";")
df_infra.rename(columns={'Date et heure de comptage': 'Date', 'Mode d√©placement': 'Mode', 'Nombre de v√©hicules': 'q'}, inplace=True)

#On clean la variable Date et on cr√©e une variable num√©ro de jour
df_infra["Date2"] = df_infra["Date"].apply(lambda x: x.split("T")[0])
df_infra["Date2"] = df_infra["Date"].apply(lambda x: x.split("+")[0])
df_infra["Date2"] = pd.to_datetime(df_infra["Date2"])
df_infra["day"] = df_infra["Date2"].apply(lambda x: x.strftime('%j'))

# On recode la variable mode de transport pour ne conserver que les modes motoris√©s.
df_infra["Mode"].value_counts()

def recodemode(a) :
        if (a == "Trottinettes + v√©los" or a == "V√©los" or a == "Trottinettes") :
            return "Non"
        else :
            return "Oui"

df_infra["Motoris√©"] = df_infra["Mode"].apply(recodemode)
df_infra["Motoris√©"][df_infra["Date2"].dt.year == 2021].value_counts()

# On cr√©e un DataFrame uniquement pour les modes motoris√©s sur 2021.
df_infra2021 = df_infra[df_infra["Motoris√©"] == "Oui"]
df_infra2021 = df_infra2021[df_infra2021["Date2"].dt.year == 2021]

# On cr√©e un DataFrame qui somme la fr√©quentation et le nombre de comptage  et qui en fait la moyenne.
funct = {"q" : "sum", "day" : "count"}
df_infra_final = df_infra2021.groupby("day").agg(funct)
df_infra_final = df_infra_final.rename(columns = {"day":"count_infra", "q":"q_infra"}) 
df_infra_final = df_infra_final.reset_index()
df_infra_final["mean_infra"] = df_infra_final["q_infra"]/df_infra_final["count_infra"]

# On merge les deux dataFrames de moyenne
df_total = df_trafic_final.merge(df_infra_final, on = "day", how = "inner")

# On mesure la corr√©lation entre mean_trafic et mean_infra
from scipy.stats import pearsonr

pearsonr(df_total["mean_trafic"],df_total["mean_infra"])

df_total.plot.scatter(x='mean_trafic', y='mean_infra', s=30);
sns.lmplot(x = 'mean_trafic', y = 'mean_infra', data = df_total);

# On cr√©e un dataFrame uniquement pour les modes v√©lo sur 2021
df_infra_velo2021 = df_infra[df_infra["Motoris√©"] == "Non"]
df_infra_velo2021 = df_infra_velo2021[df_infra_velo2021["Date2"].dt.year == 2021]

# On cr√©e un dataFrame qui somme la fr√©quentation et le nombre de comptage  et qui en fait la moyenne.
funct = {"q" : "sum", "day" : "count"}
df_infra_final_velo = df_infra_velo2021.groupby("day").agg(funct)
df_infra_final_velo = df_infra_final_velo.rename(columns = {"day":"count_infra_velo", "q":"q_infra_velo"}) 
df_infra_final_velo = df_infra_final_velo.reset_index()
df_infra_final_velo["mean_infra_velo"] = df_infra_final_velo["q_infra_velo"]/df_infra_final_velo["count_infra_velo"]
df_infra_final_velo.head()

# On merge tous les dataFrames.
df_total_ok = df_total.merge(df_infra_final_velo, on = "day", how = "inner")
df_total_ok.head()
df_total_ok.to_csv(r'C:\Users\admin\Desktop\Tricycle/trafic_2021_infra_et_traffic.csv', index=False)

"""## Preprocessing Donn√©es de compteurs v√©lo Paris 2021

Concernant les donn√©es issues des capteurs v√©lo, nous avons pu exporter les donn√©es directement sur l'ann√©e 2021 au complet.

Il nous a donc suffit de cr√©er une variable "Date" puis "day" au bon format, et de supprimer les variables inutiles, pour pouvoir ajouter ces donn√©es √† notre dataframe (via la m√©thode merge()).

Nous avons √©galement ajout√© une variable "mean_velo_compteur", qui est la somme des comptages v√©lo sur une p√©riode, divis√©e par le nombre de borne de comptage.
"""

#On int√®gre le fichier donn√©es v√©lo compteur.
df_velo = pd.read_table(r"C:\Users\admin\Desktop\Tricycle/Donn√©es v√©lo - Donn√©es de compteur.csv", sep = ",")

#On change le format de la variable 'Date' et on cr√©e la variable 'day'.
df_velo["Date2"] = pd.to_datetime(df_velo["Date"])
df_velo["day"] = df_velo["Date2"].apply(lambda x: x.strftime('%j'))

#On calcule la moyenne du nombre de v√©lo sur 1/4 d'heure et on divise par le nombre de compteurs
df_velo["mean_velo_compteur"] = df_velo_compteur["sum_velo_compteur"]/df_velo["count_velo_compteur"]

#On merge les donn√©es
df_total_ok_velo = df_total_ok.merge(df_velo, on = "day", how = "inner")

"""## Preprocessing Donn√©es m√©t√©o 2021

De m√™me, il a √©t√© ais√© pour nous de t√©l√©charger les donn√©es m√©t√©o de Paris sur l'ann√©e 2021.
Nous avons simplement cr√©√© une variable "Date" et une variable "Day" pour pouvoir ajouter les variables √† notre dataframe.
"""

#On int√®gre le fichier m√©t√©o 2021.
df_meteo = pd.read_table(r"C:\Users\admin\Desktop\Tricycle/export-paris2021.csv", sep = ",")

#On clean la variable Date et on cr√©e une variable 'day'.
df_meteo["Date2"] = pd.to_datetime(df_meteo["DATE"])
df_meteo["day"] = df_meteo["Date2"].apply(lambda x: x.strftime('%j'))

#On merge avec les donn√©es de trafic
df_complet = df_total_ok_velo_valid.merge(df_meteo, on = "day", how = "inner")

"""## Preprocessing Donn√©es de validation des transports en commun 2021

Concernant les donn√©es de validation des transports en commun, il nous a fallu :
*   Pour le r√©seau de surface, concat√©ner les 4 datasets √† notre disposition (un par trimestre) sur l'axe 0 afin d'obtenir une ann√©e compl√®te.
*   Pour le r√©seau ferr√©, concat√©ner les 2 datasets √† notre disposition (un par semestre) de la m√™me fa√ßon.

Nous avons ensuite, comme pour les donn√©es de compteurs v√©lo et de m√©t√©o, cr√©√© une variable "Date" et une variable "day" pour pouvoir ajouter les variables √† notre dataframe.

Enfin, nous avons cr√©√© une variable "sum_total_valid" qui est la somme des validations sur le r√©seau ferr√© et le r√©seau de surface sur une p√©riode.
"""

#On int√®gre le fichier donn√©es de validation.
df_valid = pd.read_table(r"C:\Users\admin\Desktop\Tricycle/validation_2021_V2.csv", sep = ",")

#On clean la variable Date et on cr√©e une variable 'day'.
df_valid["Date2"] = pd.to_datetime(df_valid["Date"])
df_valid["day"] = df_valid["Date2"].apply(lambda x: x.strftime('%j'))

#On calcule la somme des validation du r√©seau ferr√© + du r√©seau de surface
df_valid[sum_total_valid] = df_valid[sum_ferre_valid] + df_valid[sum_surface_valid] 

#On merge l'ensemble des donn√©es
df_total_ok_velo_valid = df_total_ok_velo.merge(df_valid, on = "day", how = "inner")

"""## Ajout de variables temporelles

Pour faciliter notre analyse et nos visualisations, nous avons ajout√© un certain nombre de variables temporelles √† notre dataframe :
"""

#Ajout d'un variable 'weekday', pr√©cisant le jour de la semaine (lundi, mardi, ...)
df['date'] = pd.to_datetime(df.date)
df['weekday'] = df['date'].dt.day_name()

#On ajoute une colonne pr√©cisant s'il s'agit d'un jour de la semaine ou du week-end
df["IsWeekend"] = df["date"].dt.weekday >= 5

#On ajoute une colonne pr√©cisant le mois
df['Mois'] = df.date.dt.month
df['Nom_mois'] = df.date.dt.month_name()

#On ajoute une colonne pr√©cisant le num√©ro de la semaine en question.
df["date"] = pd.to_datetime(df["date"])
df["numsem"] = df["date"].agg(lambda x : x.isocalendar()[1])
df["numsem"][0:3] = 1

#On met la variable 'date' au format jour/mois/ann√©e
df['date'] = pd.to_datetime(df['date'])
df['date'] = df['date'].apply(lambda x: x.strftime('%d/%m/%Y'))

"""Nous avons √©galement ajout√© une variable ‚Äòtypejour‚Äô = une variable cat√©gorielle qui divise les jours de l‚Äôann√©e en : jours de vacances scolaires, jours f√©ri√©s (hors vacances), weekend (hors vacances) et jours de la semaine (hors vacances). A noter que cette variable n‚Äôa pas √©t√© cr√©√©e via une formule mais fusionn√©e au dataframe sous excel apr√®s avoir √©t√© cod√©e √† la main.

A l'issue de ces √©tapes de preprocessing, un nouveau dataframe est obtenu, compilant l'ensemble des donn√©es.
Etant donn√© la dur√©e de traitement du code, nous avons export√© ce dataframe sous le nom "DataFrame_tricycle.csv" afin d'all√©ger ce notebook.

# üåû Charger "DataFrame_tricycle.csv" et √©x√©cuter √† partir d'ici 
# Import des donn√©es et des packages
"""

# Commented out IPython magic to ensure Python compatibility.
#Importation des packages n√©cessaires √† l'analyse
# %matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from datetime import datetime, timedelta

from sklearn.exceptions import ConvergenceWarning
import warnings
from sklearn.exceptions import DataConversionWarning
warnings.filterwarnings(action='ignore', category=ConvergenceWarning)

#On importe notre dataframe
df = pd.read_csv("/content/DataFrame_tricycle.csv", sep=";")

# Visualisation du dataframe modifi√©
df.head()

"""## Ajout de colonnes de calculs comptage

*** Expliquer les calculs qui suivent et leurs objectifs + le placer dans la partie pr√©-processing***
"""

# Cr√©ation des variables "part du v√©lo dans le trafic" sur une base moyenne horaire commune :

# On divise le total de la fr√©quentation quotidienne des TC par 24 pour obtenir la moyenne horaire
df["mean_total_valid"] = df["sum_total_valid"]/24

# Pour obtenir la par du v√©lo dans le trafic par source de donn√©e :
# On divise la moyenne v√©lo horaire par la somme de toutes les moyennes horaires des diff√©rentes modes (mea_velo compteur est multipli√© par 4 car c'est l'expression d'une moyenne par quart d'heure)
df["part_velo_compteur"] = (df["mean_velo_compteur"]*4) / ((df["mean_velo_compteur"]*4) + df["mean_trafic_compteur"] + (df["sum_total_valid"]/24)) * 100
df["part_velo_infra"] = df["mean_velo_infra"] / (df["mean_velo_infra"] + df["mean_trafic_infra"] + (df["sum_total_valid"]/24)) * 100

"""## Nettoyage du dataset

Nous nettoyons les donn√©es du dataframe, en passant tous les noms de colonne en minuscule et en rempla√ßant les caract√®res sp√©ciaux par des caract√®res classiques.
"""

# On passe tous les noms de colonne en minuscule
df.columns = df.columns.str.lower()

#On remplace les caract√®res invalides pr√©sents dans la colonne "opinion" par les lettres correspondantes
df.opinion = df.opinion.str.replace("√É¬©", "√©")
df.opinion = df.opinion.str.replace("√É¬®", "√®")

"""# Analyse Exploratoire des donn√©es

Nous avons ensuite inspect√© nos donn√©es pour s'assurer de leur validit√©, de leur pr√©cision et de leur coh√©rence, √† la fois sur la forme et sur le fond.

## Analyse de la forme des donn√©es
"""

# le data frame est compos√© de 365 lignes et 53 variables

df.shape

# On calcul le nombre de chaque cat√©gorie de variables en fonction de leur type

print(f"Types de variables pr√©sentes dans le dataframe : \n\n{df.dtypes.value_counts()}")

"""## Valeurs manquantes et doublons"""

# Visualisation des valeurs manquantes
print(f" Valeurs manquantes contenues dans le dataframe = {df.isna().sum().sum()}")

# Visualisation des doublons
print(f" Doublons contenus dans le dataframe = {df.duplicated().sum()}")

"""# D√©termination de la variable cible

A ce stade, nous pouvons conna√Ætre la fr√©quentation v√©lo gr√¢ce √† 2 types de donn√©es :
- les donn√©es multimodales issues des capteurs infrarouges
- les donn√©es de trafic routier et v√©lo issues des capteurs classiques

Nous cherchons donc √† d√©terminer lesquelles seront les plus pertinentes √† utiliser dans notre mod√©lisation. Ci-dessous quelques premi√®res visualisations qui permettent de comparer les deux mesures :
"""

#On instance une carte de couleur
my_cmap = plt.get_cmap("viridis")

#On instance une figure
plt.figure(figsize = (20,10))
#On compare la moyenne du trafic v√©lo (via compteurs permanents) et la moyenne du trafic v√©lo + trotinnettes (via capteurs infra) via un nuage de points
plt.subplot(221)
plt.scatter("mean_velo_compteur", "mean_velo_infra",c = 'mois', cmap = "viridis" , data = df)
plt.plot((df.mean_velo_compteur.min(), df.mean_velo_compteur.max()),(df.mean_velo_infra.min(), df.mean_velo_infra.max()))

#On ajoute les l√©gendes
plt.xlabel("Donn√©es de trafic v√©lo (compteur)")
plt.ylabel("Donn√©es de trafic v√©lo (infrarouge)")
plt.title("Trafic v√©lo")
plt.suptitle("Comparaison des donn√©es de compteur vs cam√©ra infrarouge par mode", fontsize = 25);

#On cr√©e une figure et on compare la moyenne du trafic routier (via compteurs permanents) et la moyenne du trafic routier (via capteurs infra) via un nuage de points
plt.subplot(222)
plt.scatter(x = "mean_trafic_compteur", y = "mean_trafic_infra", c = 'mois', cmap = "viridis", data = df )
plt.plot((df.mean_trafic_compteur.min(), df.mean_trafic_compteur.max()),(df.mean_trafic_infra.min(), df.mean_trafic_infra.max()))
#On ajoute les l√©gendes
plt.xlabel("Donn√©es de trafic routier (compteur)")
plt.ylabel("Donn√©es de trafic routier (infrarouge)")
plt.title("Trafic routier");

#On compare ensuite la moyenne du trafic par mois pour le trafic routier et v√©lo, sur les donn√©es de compteurs et les donn√©es infra

#On instance une figure et on cr√©e 4 graphiques en barre avec leurs l√©gendes
plt.figure(figsize = (15,15))
plt.subplot(223)
plt.bar("nom_mois", "mean_trafic_compteur", data = df, color = 'tab:blue' )
plt.xticks(rotation = 60)
plt.title("Trafic routier par mois (compteur en veh. /h)")

plt.subplot(224)
plt.bar("nom_mois", "mean_trafic_infra", color = "tab:red", data = df)
plt.title("Trafic routier par mois (infrarouge en veh. /h)")
plt.xticks(rotation = 60)

plt.subplot(221)
plt.bar("nom_mois", df["mean_velo_compteur"]*4, data = df, color = 'tab:blue')
plt.title("Trafic v√©lo par mois (compteur en velo/h)")
plt.xticks(rotation = 60)

plt.subplot(222)
plt.bar("nom_mois", "mean_velo_infra", data = df ,color = "tab:red")
plt.title("Trafic v√©lo par mois (infrarouge en velo/h)")
plt.xticks(rotation = 60)
plt.suptitle("Trafic moyen par mois par mode", fontsize = 20);

#Enfin, on compare le nombre de comptages par mois selon le mode de comptage

#On instance une figure et on cr√©e 4 graphiques en barre avec leurs l√©gendes
plt.figure(figsize = (15,15))
plt.subplot(223)
plt.bar("nom_mois", "count_trafic_compteur", data = df, color = 'tab:blue' )
plt.xticks(rotation = 60)
plt.title("Comptage routier total par mois (compteur)")

plt.subplot(224)
plt.bar("nom_mois", "count_trafic_infra", color = "tab:red", data = df)
plt.title("Comptage routier total par mois (infrarouge)")
plt.xticks(rotation = 60)

plt.subplot(221)
plt.bar("nom_mois", "count_velo_compteur", data = df, color = 'tab:blue')
plt.title("Comptage v√©lo total par mois (compteur)")
plt.xticks(rotation = 60)

plt.subplot(222)
plt.bar("nom_mois", "count_velo_infra", data = df ,color = "tab:red")
plt.title("Comptage v√©lo total par mois (infrarouge)")
plt.xticks(rotation = 60)
plt.suptitle("Volume de comptage par mois par mode", fontsize = 20);

"""Par ailleurs, pour v√©rifier s'il existe une diff√©rence importante entre les deux types de comptage pour expliquer la part du v√©lo dans l'ensemble des d√©placements (routier, transports en communs et v√©lo) √† Paris, nous avons compar√© la part du v√©lo mesur√©e par capteurs infrarouges et la part du v√©lo mesur√©e par les capteurs permanents :"""

#On importe FuncFormatter depuis matplotlib.ticker
from matplotlib.ticker import FuncFormatter
import matplotlib.ticker as mtick

#Comparaison de la part trafic v√©lo mensuelle issue des donn√©es infrarouge vs des compteurs
fig, ax1 = plt.subplots(figsize = (20,9))  
color = 'tab:red'

ind_s = np.arange(len(set(df.numsem))) #indice hebdo
ind_m = np.arange(len(set(df.mois))) #indice mensuel

#width = 0.35  

#On ajoute les l√©gendes
ax1.set_xlabel('mois')  
ax1.set_ylabel('part du trafic v√©lo (infrarouge)', color = color)  
ax1.plot(ind_s, df.part_velo_infra.groupby(df["numsem"]).mean(),  color = color, linewidth=3, marker = 'o', markersize = 7 ) #line hebdo
#ax1.plot(ind_m, df.mean_velo_infra.groupby(df["mois"]).mean(),  color = color, linewidth=3 )  #line mensuelle


# on instancie une liste qui divise l'ann√©e en 12 segments relatifs aux 52 semaines pour positionner nos labels sur l'abscisse
liste_mois = []
y = 0
for x in range(0,12) :
  liste_mois.append(y)
  y = y + (52/12)

#On ajoute les l√©gendes
ax1.tick_params(axis ='y', labelcolor = color)  
ax1.grid(axis = "x", linestyle='dotted')
plt.xticks( liste_mois ,['Jan', 'Fev', 'Mar', 'Avr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] ) #axe hebdo
#plt.xticks( [0,1,2,3,4,5,6,7,8,9,10,11],['Jan', 'Fev', 'Mar', 'Avr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] ) #axe mensuel

ax2 = ax1.twinx()  

#On ajoute les l√©gendes
color = 'tab:blue'
ax2.set_ylabel('part du trafic v√©lo (compteur)', color = color)  
ax2.plot(ind_s, df["part_velo_compteur"].groupby(df["numsem"]).mean(),  color = color, linewidth=3, marker = 'o', markersize = 7 ) #line hebdo
#ax2.plot(ind_m, df["mean_velo_compteur"].groupby(df["mois"]).mean(),  color = color, linewidth=3 ) #line mensuelle

#On reformate les √©tiquettes de l'axe des ordonn√©es en pourcentage
ax2.tick_params(axis ='y', labelcolor = color)  
ax1.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))
ax2.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))

plt.title('Comparaison de la part trafic v√©lo hebdomadaire issue des donn√©es infrarouge vs des compteurs', fontweight ="bold")  
  
plt.show();

"""# Analyse de la variable cible"""

# Examen de la variable cible (target)
df['mean_velo_compteur'].describe()

#On cr√©e un boxplot de la variable cible pour en analyser la distribution
plt.figure(figsize = (7, 7))
plt.boxplot((df.mean_velo_compteur))

#On ajoute les l√©gendes
plt.title('Boxplot de la variable cible (mean_velo_compteur)')
plt.ylabel("Moyenne de comptage v√©los par 1/4 d'heure")
plt.axes([0.65, 0.65, 0.2, 0.15], facecolor='#ffe5c1')
plt.hist(df.mean_velo_compteur, color='#FFC575')
plt.xlabel('Distribution');

#On cr√©e un bloxpot de la variable cible par mois pour en analyser la distribution

#On cr√©e une boucle qui ajoute un mois apr√®s l'autre
l=list()
for i in df.mois.unique():
    l.append(df[df['mois'] == i]['mean_velo_compteur'])
plt.figure(figsize = (15,7))
plt.boxplot(l)

#On ajoute les l√©gendes
plt.xticks(range(1,13),df.mois.unique())
plt.xlabel("Mois")
plt.ylabel("Moyenne de comptage v√©los par 1/4 d'heure")
plt.title("Boxplot de la variable cible (mean_velo_compteur) par mois")
plt.show();

#Comparaison de la part trafic v√©lo mensuelle issue des donn√©es infrarouge vs des compteurs
fig, ax1 = plt.subplots(figsize = (20,9))  
color = 'tab:blue'

ind_m = np.arange(len(set(df.mois))) #indice mensuel


ax1.set_xlabel('mois')  
ax1.set_ylabel('moyenne du trafic v√©lo quotidienne (compteur)', color = color)  
ax1.plot(ind_m, df.mean_velo_compteur.groupby(df["mois"]).mean()*4,  color = color, linewidth=3, marker = 'o', markersize = 10 )  #line mensuelle

ax1.tick_params(axis ='y', labelcolor = color)  
ax1.grid(axis = "x", linestyle='dotted')
plt.xticks( [0,1,2,3,4,5,6,7,8,9,10,11],['Jan', 'Fev', 'Mar', 'Avr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] ) #axe mensuel

ax2 = ax1.twinx()  

color = 'tab:green'
ax2.set_ylabel('part du trafic v√©lo en % de trafic (compteur)', color = color)  
ax2.plot(ind_m, df["part_velo_compteur"].groupby(df["mois"]).mean(),  color = color, linewidth=3, marker = 'o', markersize = 10 ) #line mensuelle
ax2.tick_params(axis ='y', labelcolor = color)  

#On reformate les √©tiquettes de l'axe des ordonn√©es en pourcentage
ax2.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))

plt.title('Comparaison de la moyenne de trafic v√©lo horaire mensuelle avec la part v√©lo mensuelle dans le trafic', fontweight ="bold")  
  
plt.show();

# On cr√©e ici un graphique comparant au quotidien l'expression de la moyenne quotidienne du trafic v√©lo et de la moyenne glissante sur 30 jours
fig, ax1 = plt.subplots(figsize = (20,9))  
color = 'tab:blue'


ax1.set_xlabel('mois')  
ax1.set_ylabel('moyenne du trafic v√©lo quotidienne (compteur)', color = color)  
ax1.plot(df.day, df.mean_velo_compteur,  color = color, linewidth=3 ) #line quotidienne

ax1.tick_params(axis ='y', labelcolor = color)  
ax1.grid(axis = "x", linestyle='dotted')
plt.xticks( [1,30,60,90,120,150,180,210,240,270,300,330],['Jan', 'Fev', 'Mar', 'Avr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] ) #axe quotidien

ax2 = ax1.twinx()  

color = 'tab:green'
ax2.set_ylabel('moyenne glissante sur 30 jours du trafic v√©lo (compteur)', color = color)  
ax2.plot(df.day, df["glissmean_velo_compteur"],  color = color, linewidth=3 ) #line quotidienne

ax2.tick_params(axis ='y', labelcolor = color)  

plt.title('Comparaison de la moyenne de trafic v√©lo horaire mensuelle avec la moyenne glissante de trafic v√©lo sur 30 jours', fontweight ="bold")  
  
plt.show();

# On cr√©e ici un graphique comparant au quotidien l'expression de la moyenne quotidienne du trafic v√©lo et de la moyenne des trends google sur la th√©matique du v√©lo
fig, ax1 = plt.subplots(figsize = (20,9))  
color = 'tab:blue'


ax1.set_xlabel('mois')  
ax1.set_ylabel('moyenne du trafic v√©lo quotidienne (compteur)', color = color)  
ax1.plot(df.day, df.mean_velo_compteur,  color = color, linewidth=3 ) #line quotidienne

ax1.tick_params(axis ='y', labelcolor = color)  
ax1.grid(axis = "x", linestyle='dotted')
plt.xticks( [1,30,60,90,120,150,180,210,240,270,300,330],['Jan', 'Fev', 'Mar', 'Avr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] ) #axe quotidien

ax2 = ax1.twinx()  

color = 'tab:green'
ax2.set_ylabel('moyenne glissante sur 90 jours des trends google autour du v√©lo', color = color)  
ax2.plot(df.day, df["trend_glissmean_90"],  color = color, linewidth=3 ) #line quotidienne

ax2.tick_params(axis ='y', labelcolor = color)  

plt.title('Comparaison de la moyenne de trafic v√©lo horaire mensuelle avec la moyenne glissante sur 90 jours des trends google autour du v√©lo', fontweight ="bold")  
  
plt.show();

"""## Analyse statistique via le test de corr√©lation de Pearson

"""

# Import des packages n√©cessaires √† l'analyse statistique
import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.stats.api import anova_lm

# Cr√©ation de la table d'analyse statistique pour le donn√©es m√©t√©orologiques
meteo_lm = ols('mean_velo_compteur ~ opinion + max_temperature_c + min_temperature_c + windspeed_max_kmh + \
  temperature_morning_c + temperature_noon_c + temperature_evening_c + precip_total_day_mm + humidity_max_percent + \
  visibility_avg_km + pressure_max_mb + cloudcover_avg_percent + heatindex_max_c + dewpoint_max_c + \
  windtemp_max_c + weather_code_morning + weather_code_noon + weather_code_evening + total_snow_mm + uv_index + sunhour + temperature_night_c' , data = df).fit()

table = anova_lm(meteo_lm)
display(table)

# Cr√©ation de la table d'analyse statistique pour le donn√©es de trafic
trafic_lm = ols('mean_velo_compteur ~ mean_trafic_compteur + mean_total_valid + glissmean_velo_compteur' , data = df).fit()
table = anova_lm(trafic_lm)

#On affiche la table et les r√©sultats
display(table)

# Cr√©ation de la table d'analyse statistique pour le donn√©es calendaires
trafic_lm = ols('mean_velo_compteur ~ mois + weekday + typejour' , data = df).fit()
table = anova_lm(trafic_lm)

#On affiche la table et les r√©sultats
display(table)

"""# Visualisation des donn√©es

## Visualisation des relations entre la variable cible et le variables explicatives

Afin de visualiser la corr√©lation entre la variable cible et les variables explicatives, nous d√©cidons de d√©couper ces variables en 3 : m√©t√©o, trafic et variables calendaires et de repr√©senter des heatmaps.
"""

#Instanciation d'une variable regroupant l'ensemble des features m√©t√©o et la variable cible
meteo_df = df[['mean_velo_compteur', 'max_temperature_c',
               'min_temperature_c', 'windspeed_max_kmh', 'temperature_morning_c',
               'temperature_noon_c', 'temperature_evening_c', 'temperature_night_c', 'precip_total_day_mm',
               'humidity_max_percent', 'visibility_avg_km', 'pressure_max_mb', 'dewpoint_max_c',
               'cloudcover_avg_percent', 'heatindex_max_c', 'total_snow_mm',
               'uv_index', 'sunhour', 'opinion']].copy()

#Visualisation des corr√©lations entre la variable cible et les features m√©t√©o via une heatmap
plt.figure(figsize=(15,10))
sns.heatmap(meteo_df.corr(), annot= True, cmap = "magma")

#On ajoute un titre au graphique
plt.title('Matrice de corr√©lation des variables m√©t√©orologiques sur la variable cible');

"""On analyse ensuite les corr√©lations entre entre la variable cible et les donn√©es de trafic. Pour cela, nous cr√©√©ons le dataframe "trafic_df"."""

##Instanciation d'une variable regroupant l'ensemble des features de trafic et la variable cible
trafic_df = df[['mean_velo_compteur', 'mean_trafic_compteur','mean_total_valid', 'glissmean_velo_compteur']].copy()

#Visualisation des corr√©lations entre la variable cible et les features m√©t√©o via une heatmap
plt.figure(figsize=(15,10))
sns.heatmap(trafic_df.corr(), annot= True, cmap = "magma")

#On ajoute un titre au graphique
plt.title('Matrice de corr√©lation des variables de trafic sur la variable cible');

"""Pour finir, on analyse les corr√©lations entre la variable cible et les variables calendaires. Pour cela, nous cr√©√©ons le dataframe "calend_df"
"""

##Instanciation d'une variable regroupant l'ensemble des features calendaires et la variable cible et transformation des variables 'object' en variables en √©chelle num√©riques
calend_df = df[['mean_velo_compteur', 'numsem', 'weekday', 'mois', 'typejour']]
calend_df['weekday'] = calend_df['weekday'].replace(dict(zip(df.weekday.unique(), [1,2,3,4,5,6,7])))
calend_df['typejour'] = calend_df['typejour'].replace(dict(zip(df.typejour.unique(), [1,4,3,2])))

#Visualisation des corr√©lations entre la variable cible et les features calendaires via une heatmap
plt.figure(figsize=(15,10))
sns.heatmap(calend_df.corr(), annot= True, cmap = "magma")

#On ajoute un titre au graphique
plt.title('Matrice de corr√©lation des variables calendaires sur la variable cible');

"""## R√©partition moyenne de l'usage v√©lo en fonction des mois et des jours de la semaine

Pour comprendre la p√©riodicit√© de l'utilisation du v√©lo au cours de l'ann√©e et au cours de la semaine, il est int√©ressant d'observer le nombre de d√©placement sur ces p√©riodes.
"""

#On cr√©e une variable 'weekday_nom', nous permettant d'obtenir le jour de la semaine (en chiffre)
weeks = {'Monday': 0, 'Tuesday' : 1, 'Wednesday' : 2, 'Thursday' : 3, 'Friday' : 4, 'Saturday' : 5, 'Sunday' : 6} 
df['weekday_num'] = df['weekday'].map(weeks) 

#On fait la somme du nombre de comptage v√©lo par jour de la semaine et on l'ordonne.
count_velo_weekday = df.groupby('weekday_num')['mean_velo_compteur'].mean()*4

#On cr√©e un graphique en barre pour observer les r√©sultats
plt.figure(figsize = (10,5))
plt.bar(count_velo_weekday.index, count_velo_weekday.values, color='teal')

#On ajoute les l√©gendes
plt.xticks([0, 1, 2, 3, 4, 5, 6,], ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche'])
plt.ylabel("moyenne horaire du trafic v√©lo par jour (donn√©es de compteur)")
plt.xlabel("Jour de la semaine");

#On cr√©e un graphique en barre repr√©sentant le nombre moyen de comptage v√©lo par type de jour et on l'ordonne.
plt.figure(figsize = (9,5))
mean_trafic_velo_typejour = df.groupby('typejour')['mean_velo_compteur'].mean()*4
plt.bar(mean_trafic_velo_typejour.index, mean_trafic_velo_typejour.values, color='teal')
plt.ylim(0)

#On ajoute les l√©gendes
plt.ylabel("Moyenne horaire du trafic v√©lo (donn√©es de compteur)")
plt.xlabel("Type Jour")
plt.title("Moyenne horaire du trafic v√©lo par type de jour");

#On cr√©e un graphique en barre repr√©sentant le nombre de comptage v√©lo par mois et on l'ordonne.
plt.figure(figsize = (9,9))
trafic_mois_velo = df.groupby('mois')['sum_velo_compteur'].sum()
plt.bar(trafic_mois_velo.index, trafic_mois_velo.values, color='teal')
plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], ['Janvier', 'F√©vrier', 'Mars', 'Avril', 'Mai', 'Juin', 'Juillet', 'Ao√ªt', 'Septembre', 'Octobre', 'Novembre', 'D√©cembre'], rotation = 60)
plt.ylim(0)

#On ajoute les l√©gendes
plt.ylabel("Somme du nombre de comptage de v√©lo (en millions")
plt.xlabel("Mois")
plt.title("Evolution du trafic de v√©lo √† Paris par mois en 2021");

"""# Mod√©lisation

### Instanciation des √©chantillons
"""

#On charge les packages n√©cessaires
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_validate
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import Ridge, LassoCV, LinearRegression
from sklearn.model_selection import \
    KFold, RepeatedKFold, GridSearchCV, \
    cross_validate, train_test_split

cv = KFold(n_splits=5, shuffle=True, random_state=123)

# On conserve les variables explicatives n√©cessaires √† notre analyse :
col_total_compteur = ["mean_trafic_compteur", 'max_temperature_c',  "mean_total_valid", 
                      'windspeed_max_kmh', 'temperature_morning_c', 'min_temperature_c',
                     'temperature_noon_c', 'temperature_evening_c', 'precip_total_day_mm',
                      'humidity_max_percent', 'visibility_avg_km', 'pressure_max_mb',
                      'cloudcover_avg_percent', 'heatindex_max_c', 'dewpoint_max_c',
                      'windtemp_max_c', 'total_snow_mm', 'uv_index', 'sunhour',
                      'temperature_night_c', "typejour", "opinion", "glissmean_velo_compteur", "nom_mois"]

# On s√©pare notre dataframe entre notre variable cible et nos variables explicatives:
feats = df[col_total_compteur]
target = df["mean_velo_compteur"]

# On dichotomise les variables cat√©gorielles :
feats = feats.join(pd.get_dummies(feats["typejour"], prefix= "jour"))
del(feats["typejour"])
feats = feats.join(pd.get_dummies(feats["opinion"], prefix= "o"))
del(feats["opinion"])
feats = feats.join(pd.get_dummies(feats["nom_mois"], prefix= "mois"))
del(feats["nom_mois"])

# On s√©pare notre dataframe en √©chantillons de test et d'entra√Ænement :
X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=(100/365), shuffle = True, random_state = 123)

# On standardise les variables :
scaler = preprocessing.StandardScaler().fit(X_train)

X_train = scaler.transform(X_train)
X_train = pd.DataFrame(X_train, index = range(0,265))
feats_col = feats.columns
scaled_col = X_train.columns
dict_col = dict(zip(scaled_col, feats_col))
X_train.rename(columns = dict_col, inplace = True)

X_test = scaler.transform(X_test)
X_test = pd.DataFrame(X_test, index = range(0,100))
X_test.rename(columns = dict_col, inplace = True)

# On d√©finit ici une fonction qui pour un mod√®le donn√© l'entra√Ænement sur les donn√©es X_train et pr√©sente ses principaux indicateurs de performances

def result_model (model, model_name) :
  
  #on  entra√Æne le mod√®le sur le dataset de train :
  model.fit(X_train, y_train)

  #on cr√©e deux array int√©grant les r√©sultats des pr√©dictions sur les √©chantillons de train et de test :
  pred_train = model.predict(X_train)
  pred_test = model.predict(X_test)

  #On affiche les RMSE et score de R2 pour les deux √©chantillons :
  print("Mod√®le "+ model_name + " - rmse (train set):", np.sqrt(mean_squared_error(pred_train,y_train)))
  print('Mod√®le '+ model_name + ' - rmse (test set):', np.sqrt(mean_squared_error(pred_test, y_test)))
  print('\nMod√®le '+ model_name + ' - score R¬≤ (train set): ' , model.score(X_train, y_train))
  print('Mod√®le '+ model_name + ' - score R¬≤ (test set): ' , model.score(X_test, y_test))

  #On observe l'alignement des pr√©dictions sur la variable cible via un scatterplot
  plt.title("Alignement des pr√©dictions avec la variable cible")
  plt.scatter(pred_test, y_test)
  plt.plot((y_test.min(), y_test.max()), (y_test.min(), y_test.max()))
  plt.show()
  ;

  # Repr√©sentation graphique des valeurs r√©siduelles sur l'√©chantillon de train
  residus_train = pred_train - y_train

  plt.scatter(y_train, residus_train, color='#980a10', s=15)
  plt.ylim(5,-5)
  plt.plot((y_train.min(), y_train.max()), (0, 0), lw=3, color='#0a5798')
  plt.title("Residual errors - train")
  plt.show()
  ;

  # Repr√©sentation graphique des valeurs r√©siduelles sur l'√©chantillon de test
  residus_test = pred_test - y_test

  plt.scatter(y_test, residus_test, color='#980a10', s=15)
  plt.ylim(5,-5)
  plt.plot((y_test.min(), y_test.max()), (0, 0), lw=3, color='#0a5798')
  plt.title("Residual errors - test")
  plt.show()
  ;

"""## Mod√©lisation par R√©gression lin√©aire

### R√©gression lin√©aire multiple
"""

#On instance notre mod√®le et on mesure ses performances
from sklearn.linear_model import LinearRegression
lr = LinearRegression()

result_model(lr, 'LinearRegression')

"""### Mod√®le Ridge"""

#On instance notre mod√®le et on mesure ses performances
from sklearn.linear_model import Ridge
ridge_reg = Ridge(alpha = 2.020211818181818, solver = 'lsqr')

result_model(ridge_reg, 'Ridge')

"""### Mod√®le Lasso"""

#On instance notre mod√®le et on mesure ses performances
from sklearn.linear_model import Lasso
model_lasso = Lasso(alpha = 0.000009, max_iter = 251, selection = "random" )

result_model(model_lasso, 'Lasso')

"""### Mod√®le Elastic Net

Il s'agit d'un m√©lange de r√©gression Ridge et Lasso qui fait ressortir un effet de regroupement lorsque des pr√©dicteurs fortement corr√©l√©s s'approchent ou s'√©loignent du mod√®le de mani√®re combin√©e.

Il est recommand√© d'utiliser ce mod√®le lorsque le nombre de pr√©dicteurs est tr√®s sup√©rieur au nombre d'observations.
"""

#On instance notre mod√®le et on mesure ses performances
from sklearn.linear_model import ElasticNetCV 
model_enCV = ElasticNetCV(l1_ratio = 0.5555599999999999, alphas = (0.001, 0.01, 0.02, 0.025, 0.05, 0.1, 0.25, 0.5, 0.8, 1.0), n_alphas=6, eps = 0.00001, fit_intercept = True)

result_model(model_enCV, 'ElasticNet')

"""## Mod√©lisation par r√©gression non lin√©aire

### XGBRegressor
"""

#On instance notre mod√®le et on mesure ses performances
from sklearn import datasets
from sklearn import metrics
from sklearn.model_selection import train_test_split
plt.style.use("ggplot")
import xgboost as xgb

xgbR = xgb.XGBRegressor(objective ='reg:squarederror',booster = 'gbtree', reg_lambda = 0.16778523489932887, 
                       reg_alpha = 0.35570469798657717, max_depth = 5, max_leaves = 0, gamma = 0.4809045226130653,
                        max_delta_step = 7 , 
                        min_child_weight = 11 , 
                        process_type = 'default',
                        subsample = 0.4977386934673367,
                       learning_rate = 0.1357718120805369, base_score = 0.48743718592964824)


result_model(xgbR, 'XGB Regressor')

"""### Decision Tree Regression

"""

#On instance notre mod√®le et on mesure ses performances

from sklearn.tree import DecisionTreeRegressor

tree=DecisionTreeRegressor(criterion = "friedman_mse", max_depth= 38, splitter = "random", random_state = 380)

result_model(tree, 'Decision Tree')

"""### Random Forest Regression"""

#On instance notre mod√®le et on mesure ses performances

from sklearn.ensemble import RandomForestRegressor

forest = RandomForestRegressor(n_estimators=23,
                             max_depth=10,
                             criterion='squared_error',random_state = 780
                            )

result_model(forest, 'Random Forest')

"""### Support Vector Regressor (SVR)"""

#On instance notre mod√®le et on mesure ses performances

from sklearn import svm
from sklearn.svm import SVR

svr = svm.SVR(kernel='rbf', gamma =0.0008299277376320178, C = 556.7593107281823, epsilon = 0.09319732441471572, tol = 0.09031070234113713)

result_model(svr, 'SVR')

"""### Nu Support Vector Regression (NuSVR)"""

#On instance notre mod√®le et on mesure ses performances

from sklearn.svm import NuSVR

Nusvr = svm.NuSVR(kernel='rbf', gamma =0.0007372372372372372, nu = 0.9897897897897898, C = 266, tol = 0.45)

result_model(Nusvr, 'NuSVR')

"""### Gaussian Process Regression (GPR)"""

#On instance notre mod√®le et on mesure ses performances
from sklearn.gaussian_process.kernels import (RBF, Matern, RationalQuadratic,ExpSineSquared, DotProduct,ConstantKernel)
from sklearn.gaussian_process.kernels import ExpSineSquared
from sklearn.gaussian_process import GaussianProcessRegressor

kernel_1 =1.0 * RBF( length_scale=1.0 , length_scale_bounds=(0.1, 10.0))

gpr = GaussianProcessRegressor(kernel = kernel_1, alpha=0.6)

result_model(gpr, 'Gaussian Process Regressor')

"""### Random Sample Consensus (RANSAC) Regression"""

#On instance notre mod√®le et on mesure ses performances
from sklearn.linear_model import RANSACRegressor

ransac = RANSACRegressor(LinearRegression(),
		max_trials=22, 		# Number of Iterations
		min_samples=32, 		# Minimum size of the sample
		loss='absolute_error', 	# Metrics for loss
		residual_threshold=2, 	# Threshold
		random_state = 399
		)

result_model(ransac, 'RANSAC')

"""### K Nearest Neighbors (KNN) Regressor

"""

#On instance notre mod√®le et on mesure ses performances

from sklearn import neighbors
knn = neighbors.KNeighborsRegressor(n_neighbors = 8, metric = "cosine", weights= 'distance' )

result_model(knn, 'KNN Regressor')

"""### BayesianRidge

"""

#On instance notre mod√®le et on mesure ses performances
from sklearn.linear_model import BayesianRidge

bayesian = BayesianRidge( n_iter=1, tol=0.00001, alpha_init = 1.35, lambda_init = 0.99665, alpha_1=10000, alpha_2=1e-100, 
                         lambda_1=1e-100, lambda_2=10000)


result_model(bayesian, 'Bayesian ridge')

"""### Multi-Layer Perceptron (MLP) Regression



"""

#On instance notre mod√®le et on mesure ses performances

from sklearn.neural_network import MLPRegressor

mlp_lbfgs = MLPRegressor(activation = 'logistic',
 learning_rate= 'invscaling',
 solver= 'lbfgs', alpha = 0.8499874371859297, batch_size = 1, tol =0, hidden_layer_sizes = (60,), random_state = 138)

result_model(mlp_lbfgs, 'MLP LBFGS')

# On instance notre mod√®le et on mesure ses performances
from sklearn.neural_network import MLPRegressor

mlp_sgd = MLPRegressor(activation = 'relu',
 learning_rate= 'adaptive',
 solver= 'sgd',  alpha = 0.01731438127090301, batch_size = 70, tol = 0, hidden_layer_sizes = (60,),learning_rate_init = 0.018364548494983278, momentum = 0, random_state = 1133)

result_model(mlp_sgd, 'MLP SGD')

"""### Kernel Ridge Regression (KRR) """

# On instance notre mod√®le et on mesure ses performances
from sklearn.kernel_ridge import KernelRidge
krr_model = KernelRidge(alpha=0.6515635451505017, kernel = 'polynomial', gamma = 0.05809045226130653, degree = 3,  coef0 = 0.7477386934673367).fit(X_train, y_train)


result_model(krr_model, 'Kernel Ridge Regression')

"""#Tableau de combinaisons de mod√®les"""

import itertools
import statistics
from sklearn.metrics import r2_score

# On instancie qui reprennent les pr√©dictions sur les √©chantillons de test et de train plus les noms de chaque mod√®les : 


list_pred_model_train = [gpr.predict(X_train), tree.predict(X_train), forest.predict(X_train), svr.predict(X_train),
                           ransac.predict(X_train), lr.predict(X_train), ridge_reg.predict(X_train),
                           model_lasso.predict(X_train), model_enCV.predict(X_train), knn.predict(X_train), Nusvr.predict(X_train), bayesian.predict(X_train), mlp_lbfgs.predict(X_train),
                         mlp_sgd.predict(X_train), xgbR.predict(X_train), krr_model.predict(X_train)]

list_pred_model_test = [gpr.predict(X_test), tree.predict(X_test), forest.predict(X_test), svr.predict(X_test),
                           ransac.predict(X_test), lr.predict(X_test), ridge_reg.predict(X_test),
                           model_lasso.predict(X_test), model_enCV.predict(X_test), knn.predict(X_test), Nusvr.predict(X_test), bayesian.predict(X_test), mlp_lbfgs.predict(X_test),
                        mlp_sgd.predict(X_test), xgbR.predict(X_test), krr_model.predict(X_test)]

list_model_name = ['GPR', 'tree', 'forest', 'svr', 'ransac', 'linear', 
                      'ridge', 'lasso', 'ElasticNEt', 'KNN', 'NuSVR', 'Bayesian', 'MLP_LBFGS', 'MLP_SGD', 'XBG', 'KRR']

# On cr√©e une boucle 'for' qui √©value toutes les combinaisons de mod√®les sur la moyenne des r√©sidus et sur l'√©cart type :

# on fixe un nombre de combinaisons (itr) comrpises entre 1 (mod√®le unique) et une combinaison de tous les mod√®les
itr = range(1,len(list_model_name)+1)
itr = [1,2,3]
result = pd.DataFrame([])
for y in itr :

  # On instancie une colonne qui va recevoir la moyenne des pr√©dictions
  mean_model_train = []
  df_pred_train = pd.DataFrame(itertools.combinations(list_pred_model_train,y), index = itertools.combinations(list_model_name,y))
  
  mean_model_test = []
  df_pred_test = pd.DataFrame(itertools.combinations(list_pred_model_test,y), index = itertools.combinations(list_model_name,y))

  for r in list(range(0,len(df_pred_train))) :
    mean_model_train.append(list(range(0,265)))
  df_pred_train["pred"] = mean_model_train

  for r in list(range(0,len(df_pred_test))) :
    mean_model_test.append(list(range(0,100)))
  df_pred_test["pred"] = mean_model_test

  # On cr√©e une boucle qui va calculer la moyenne pour chaque target de la pr√©diction de l'ensemble des combinaisons de mod√®les :
  for row in list(range(0,265)) :
    for combo in list(range(0,len(df_pred_train))) :
      list_mean_train = []
      for x in list(range(0,y)) :
        list_mean_train.append(df_pred_train[x][combo][row])
      df_pred_train["pred"][combo][row] = statistics.median(list_mean_train)
  
  # On cr√©e une boucle qui va calculer le score de R2 pour chaque combinaisons de mod√®les :
  list_train_score = []
  list_train_rmse = []
  for combo2 in list(range(0,len(df_pred_train))) :
    list_train_score.append(r2_score(y_train, df_pred_train["pred"][combo2]))
    list_train_rmse.append(np.sqrt(mean_squared_error(df_pred_train["pred"][combo2], y_train)))
  df_pred_train["train_score"] = list_train_score
  df_pred_train["train_rmse"] = list_train_rmse

 # On cr√©e une boucle qui va calculer la moyenne pour chaque target de la pr√©diction de l'ensemble des combinaisons de mod√®les :
  for row in list(range(0,100)) :
    for combo in list(range(0,len(df_pred_test))) :
      list_mean_test = []
      for x in list(range(0,y)) :
        list_mean_test.append(df_pred_test[x][combo][row])
      df_pred_test["pred"][combo][row] = statistics.median(list_mean_test)
  
  # On cr√©e une boucle qui va calculer le score de R2 pour chaque combinaisons de mod√®les :
  list_test_score = []
  list_test_rmse = []
  for combo2 in list(range(0,len(df_pred_test))) :
    list_test_score.append(r2_score(y_test, df_pred_test["pred"][combo2]))
    list_test_rmse.append(np.sqrt(mean_squared_error(df_pred_test["pred"][combo2], y_test)))
  df_pred_test["test_score"] = list_test_score
  df_pred_test["test_rmse"] = list_test_rmse

  # On cr√©e un DataFrame temporaire qui va accueillir les deux metrics et se fusionner avec result :
  df_combi = pd.DataFrame([])
  df_combi["train score"] = df_pred_train["train_score"]
  df_combi["test score"] = df_pred_test["test_score"]
  df_combi["train_rmse"] = df_pred_train["train_rmse"]
  df_combi["test_rmse"] = df_pred_test["test_rmse"]

  frames = (result, df_combi)
  result = pd.concat(frames, join = "outer")


# On cr√©e une variable qui compte le nombre de combinaisons totales test√©es :
result = result.reset_index()
result['nb_combo'] = result['index'].apply(lambda x : len(x))

# Vue des 50 combinaisons de mod√®les les plus performantes sur le test score
result.sort_values(by = "test score", key = abs, ascending = False).head(50)

# Tableau r√©cap des r√©sultats par mod√®les uniques

result[result['nb_combo'] == 1].sort_values(by = "test score", key = abs, ascending = False)

"""# Visualisation des performances des mod√®les"""

# Instanciation de trois listes (pr√©dictions sur le X_test par mod√®le, nom des mod√®les test√©s, et score des mod√®les sur le X_test)

list_pred_model_test = [Nusvr.predict(X_test), 
                        krr_model.predict(X_test),
                        mlp_sgd.predict(X_test),
                        svr.predict(X_test),
                        mlp_lbfgs.predict(X_test),                        
                        gpr.predict(X_test),
                        xgbR.predict(X_test),
                        ransac.predict(X_test),
                        forest.predict(X_test),
                        lr.predict(X_test),
                        model_enCV.predict(X_test),
                        model_lasso.predict(X_test),
                        ridge_reg.predict(X_test),
                        bayesian.predict(X_test),
                        knn.predict(X_test),
                        tree.predict(X_test)]

list_model_name = ['NuSVR',
                   'KRR',
                   'MLP_SGD',
                   'svr',
                   'MLP_LBFGS',
                   'GPR',
                   'XBG',
                   'ransac',
                   'forest',
                   'linear', 
                   'ElasticNEt',
                   'lasso',
                   'ridge',
                   'Bayesian',
                   'KNN',                   
                   'tree']

list_R2test = [Nusvr.score(X_test, y_test), 
                        krr_model.score(X_test, y_test),
                        mlp_sgd.score(X_test, y_test),
                        svr.score(X_test, y_test),
                        mlp_lbfgs.score(X_test, y_test),                        
                        gpr.score(X_test, y_test),
                        xgbR.score(X_test, y_test),
                        ransac.score(X_test, y_test),
                        forest.score(X_test, y_test),
                        lr.score(X_test, y_test),
                        model_enCV.score(X_test, y_test),
                        model_lasso.score(X_test, y_test),
                        ridge_reg.score(X_test, y_test),
                        bayesian.score(X_test, y_test),
                        knn.score(X_test, y_test),
                        tree.score(X_test,y_test)]



# On cr√©e une boucle pour afficher sous forme graphique les performances de chacun des mod√®les
# 4 subplot de 4 colonnes s'encha√Ænent avec √† chaque fois :
    # le rapport entre les pr√©dictions et les valeurs r√©elles
    # deux lignes qui bleues d√©limitent une marge d'erreur "acceptable" de + ou - 1 par rapport √† la moyenne de trafic (1/4 d'h) r√©elle
    # le rappel du score de R2 sur l'√©chantillon test

sp = 1
x = 0
seq = range(4)
for s in seq :
    plt.figure(figsize=(30,7))
    a = sp + 140
    
    plt.subplot(a)
    plt.scatter(y_test, list_pred_model_test[x],c = abs(y_test - list_pred_model_test[x]) >= 1, cmap = 'coolwarm')
    plt.plot(y_test,y_test +1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.plot(y_test,y_test - 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.title(list_model_name[x] + " ( R2 = " + str(list_R2test[x]) + ")")
    plt.xlabel("valeur r√©elle")
    plt.ylabel("valeur pr√©dite")
    
    plt.subplot(a+1)
    plt.scatter(y_test, list_pred_model_test[x+1],c = abs(y_test - list_pred_model_test[x+1]) >= 1, cmap = 'coolwarm')
    plt.plot(y_test,y_test + 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.plot(y_test,y_test - 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.title(list_model_name[x+1] + " ( R2 = " + str(list_R2test[x+1]) + ")")
    plt.xlabel("valeur r√©elle")
    plt.ylabel("valeur pr√©dite")
    
    plt.subplot(a+2)
    plt.scatter(y_test, list_pred_model_test[x+2],c = abs(y_test - list_pred_model_test[x+2]) >= 1, cmap = 'coolwarm')
    plt.plot(y_test,y_test + 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.plot(y_test,y_test - 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.title(list_model_name[x+2] + " ( R2 = " + str(list_R2test[x+2]) + ")")
    plt.xlabel("valeur r√©elle")
    plt.ylabel("valeur pr√©dite")
    
    plt.subplot(a+3)
    plt.scatter(y_test, list_pred_model_test[x+3],c = abs(y_test - list_pred_model_test[x+3]) >= 1, cmap = 'coolwarm')
    plt.plot(y_test,y_test + 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.plot(y_test,y_test - 1, color = 'blue', linewidth = 0.5, linestyle = '--')
    plt.title(list_model_name[x+3] + " ( R2 = " + str(list_R2test[x+3]) + ")")
    plt.xlabel("valeur r√©elle")
    plt.ylabel("valeur pr√©dite")   
    
    plt.show()
    
    x = x+4
    ;

"""# R√©duction de dimension

## SKBest
"""

#On importe SelectKBest et f_regression
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression

#On instancie deux listes : une qui reprend cumule l'ensemble des mod√®les test√©s, l'autre leurs noms en format 'str' :

liste_model = [gpr, tree, forest, svr,
                           ransac, lr, ridge_reg,
                           model_lasso, model_enCV, knn, Nusvr, bayesian, mlp_lbfgs,
                        mlp_sgd, xgbR, krr_model]
                        
list_model_name = ['GPR', 'tree', 'forest', 'svr', 'ransac', 'linear', 
                      'ridge', 'lasso', 'ElasticNEt', 'KNN', 'NuSVR', 'Bayesian', 'MLP_LBFGS', 'MLP_SGD', 'XBG', 'KRR']

# On cr√©e ici une boucle for qui permet pour chaque mod√®le ainsi cr√©e de tester les combinaisons de variables les plus optimales via la m√©thode du SelectKbest :


# On instancie d'abord une boucle for qui va r√©p√©ter les op√©rations suivantes pour tous les mod√®les test√©s :
x = 0
for model in liste_model :
  # On instancie d'abord deux listes vides pr√™tes √† recevoir les r√©sultats du test pour chaque combinaisons de variables
  train_score_per_nbvar = []
  test_score_per_nbvar = []
  # on d√©finit la range du nombre de variable √† tester comme le nombre de variable total pr√©sent dans X_train
  range_sk = range(1,len(X_train.columns)+1)
 
  # On ensuite pour un mod√®le donn√© une boucle de SelectKbest qui va mesurer ses performances en fonction du nombre de variables possibles :
  for nbvar in range_sk :
    
    # on instancie le SelectKbest et on l'entra√Æne sur les donn√©es d'entra√Ænement
    sk = SelectKBest(f_regression, k= nbvar)
    sk.fit(X=X_train, y=y_train)
    
    # on transforme ensuite nos datasets de test et de train en fonction du nombre de variables s√©lectionn√©es
    sk_train = sk.transform(X_train)
    sk_test = sk.transform(X_test)

    # on fit le mod√®le sur ces nouveaux datasets et on √©crit dans les listes pr√©c√©dentes ses r√©sultats (R2 Train et Test)
    model.fit(sk_train, y_train)
    train_score_per_nbvar.append(model.score(sk_train, y_train))
    test_score_per_nbvar.append(model.score(sk_test, y_test))
  
  # On instancie un dataframe avec les r√©sultats des deux listes puis on isole l'index du meilleur ["test_score"]
  score_per_nbvar = pd.DataFrame(zip(train_score_per_nbvar,test_score_per_nbvar), columns = ["train_score","test_score"], index = range(1,len(X_train.columns)+1))
  test_max = score_per_nbvar[score_per_nbvar["test_score"] == score_per_nbvar["test_score"].max()].index[0]
  
  # pour finir pour chaque mod√®le test√© on cr√©e un graph repr√©sentant la variation des scores de train et test en fonction du nombre de variables s√©lectionn√©es
  # et dans lequel on affiche un axe vertical sur la position correspondant au meilleur r√©sultat de test score
  plt.figure(figsize = (20,5))
  plt.plot(range_sk,train_score_per_nbvar, color = "red", label = "train_score" )
  plt.plot(range_sk,test_score_per_nbvar, color = "green", label = "test_score" )
  plt.title( str(list_model_name[x]) + " : √©volution du r2 train et test en fonction du nombre de variables s√©lectionn√©es")
  plt.ylabel("r2")
  plt.xlabel("Nombre de variables s√©lectionn√©es")
  plt.axvline(x=test_max, color = "green", label = "test score max pour r2 = " + str(test_max) ,linestyle='--')
  plt.legend()
  x = x + 1
  print(x)
  ;

sk = SelectKBest(f_regression, k= 23)
sk.fit(X=feats, y=target)

sk_train = sk.transform(X_train)
sk_test = sk.transform(X_test)

krr_model.fit(sk_train, y_train)

print("train score pour " + str(21) + " variables : " + str(krr_model.score(sk_train, y_train)))
print("test score pour " + str(21) + " variables : " + str(krr_model.score(sk_test, y_test)))
variables_select = pd.DataFrame(feats.columns[sk.get_support()], index = range(0,23), columns = ["var_sel"])

X_train_opt = X_train[feats.columns[sk.get_support()]]
X_test_opt = X_test[feats.columns[sk.get_support()]]

X_train_opt.info()

"""## Analyse des Composantes Principales (ACP)"""

from sklearn.decomposition import PCA


# On test d'abord une ACP sur l'ensemble des variables explicatives

# Instanciation de l'ACP et transformation des datasets X_train et X_test
pca = PCA(svd_solver = 'randomized')

Coord_train = pca.fit_transform(X_train)
Coord_test = pca.transform(X_test)

# Affichage des valeurs propres par facteurs
print('Les valeurs propres sont :', pca.explained_variance_)

# Repr√©sentation des valeurs propres dans un graphique
plt.plot(range(0, 42), pca.explained_variance_)
plt.xlabel('Nombre de facteurs')
plt.ylabel('Valeurs propres');
plt.show()

# Affichage du ratio de variance expliqu√©e par facteur
print('Les ratio sont :', pca.explained_variance_ratio_)

# Repr√©sentation grapgique de la somme cumulative de la variance expliqu√©e
plt.plot(np.arange(1, 43), np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Factor number')
plt.ylabel('Cumsum');
plt.show()

# Instanciation de deux listes des ratios d'explication de la variance, l'une contenant les premi√®res dimensions les plus explicatives, la seconde le reste des dimensions
L1 = list(pca.explained_variance_ratio_[0:18])
L1.append(sum(pca.explained_variance_ratio_[18:43]))

# Cr√©ation d'un graph repr√©sentant la part d'explication de la variance des principales dimensions + la somme des autres
plt.pie(L1, labels=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18','Autres'], 
        autopct='%1.0f%%');

# Instanciation des dataframe de Train et Test transform√©s par l'ACP sur les principales dimensions
X_train_ACP_1 = pd.DataFrame(Coord_train[:,:18], index = range(0,265))
X_test_ACP_1 = pd.DataFrame(Coord_test[:,:18], index = range(0,100))

# On test ensuite l'ACP uniquement sur les variables m√©t√©os

# On isole en premier lieu les variables m√©t√©os √† injecter au mod√®le
var_m√©t√©o = ['max_temperature_c','min_temperature_c', 'windspeed_max_kmh',
       'temperature_morning_c', 'temperature_noon_c', 'temperature_evening_c',
       'precip_total_day_mm', 'humidity_max_percent', 'visibility_avg_km',
       'pressure_max_mb', 'cloudcover_avg_percent', 'heatindex_max_c',
       'dewpoint_max_c', 'windtemp_max_c', 'total_snow_mm', 'uv_index',
       'sunhour', 'temperature_night_c', 
       'o_m√©t√©o correcte',
       'o_m√©t√©o d√©favorable', 'o_m√©t√©o favorable', 'o_m√©t√©o id√©ale',
       'o_m√©t√©o tr√®s d√©favorable']

X_m√©t√©o_train = X_train[var_m√©t√©o]
X_m√©t√©o_test = X_test[var_m√©t√©o]

# Instanciation de l'ACP et transformation des datasets X_train et X_test
    
pca_m = PCA()

Coord_m√©t√©o_train = pca_m.fit_transform(X_m√©t√©o_train)
Coord_m√©t√©o_test = pca_m.transform(X_m√©t√©o_test)

# Affichage des valeurs propres par facteurs
print('Les valeurs propres sont :', pca_m.explained_variance_)

# Repr√©sentation des valeurs propres dans un graphique
plt.plot(range(0, 23), pca_m.explained_variance_)
plt.xlabel('Nombre de facteurs')
plt.ylabel('Valeurs propres');
plt.show()

# Affichage du ratio de variance expliqu√©e par facteur
print('Les ratio sont :', pca_m.explained_variance_ratio_)


# Repr√©sentation grapgique de la somme cumulative de la variance expliqu√©e
plt.plot(np.arange(1, 24), np.cumsum(pca_m.explained_variance_ratio_))
plt.xlabel('Factor number')
plt.ylabel('Cumsum');
plt.show()

# Instanciation de deux listes des ratios d'explication de la variance, l'une contenant les premi√®res dimensions les plus explicatives, la seconde le reste des dimensions
L1 = list(pca_m.explained_variance_ratio_[0:13])
L1.append(sum(pca_m.explained_variance_ratio_[13:31]))

# Cr√©ation d'un graph repr√©sentant la part d'explication de la variance des principales dimensions + la somme des autres
plt.pie(L1, labels=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12','PC13','Autres'], 
        autopct='%1.0f%%');


# Cr√©ation de liste des variables non m√©t√©orologiques par diff√©rence avec la liste des variables m√©t√©os
difference_1 = set(X_train_m√©t√©o.columns).difference(set(feats.columns))
difference_2 = set(feats.columns).difference(set(X_train_m√©t√©o.columns))
var_non_m√©t√©o = list(difference_1.union(difference_2))

# Instanciation des dataframe de Train et Test transform√©s par l'ACP sur les principales dimensions
X_train_ACP2 = pd.concat((X_train[var_non_m√©t√©o],(pd.DataFrame(Coord_m√©t√©o_train[:,:13],index = range(0,265)))), join = 'inner', axis = 1)
X_test_ACP2 = pd.concat((X_test[var_non_m√©t√©o],(pd.DataFrame(Coord_m√©t√©o_test[:,:13],index = range(0,100)))), join = 'inner', axis = 1)

"""# Interpr√©tabilit√©

## Interpr√©tabilit√© du mod√®le de regression lin√©aire
"""

#Impression des coefficients
print(lr.coef_)

#Repr√©sentation des coefficients
pd.Series(lr.coef_, X_train.columns).sort_values(ascending=False).plot(kind='barh', figsize=(20,15));

cat_list = ['D√©placement', 'M√©t√©o', 'D√©placement', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'Tendance',
                                      'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 
            'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire']

#On imprime le dataframe
result_LR = pd.DataFrame(zip(lr.coef_, X_train.columns), index = range(0,42), columns = ['Coef', 'Feature'])
result_LR["cat_var"] = cat_list
result_LR["coef_abs"] = result_LR.Coef.apply(lambda x :  abs(x))
result_LR["importance_percent"] = result_LR.coef_abs.apply(lambda x :  x/result_LR.coef_abs.sum())
result_LR

R = result_LR["importance_percent"].groupby(result_LR["cat_var"]).sum().sort_values(ascending = False)

plt.figure(figsize = (5,5))
plt.pie( R ,labels = R.index, autopct = '%1.0f%%', textprops={'fontsize': 14}, colors= ['tab:orange', 'tab:blue', 'tab:purple', 'tab:green'], startangle = 90, counterclock = False)
plt.title("Importance des features par cat√©gories de variables",fontdict = {'fontsize' : 20}, pad = 50)
;

"""## Interpr√©tabilit√© du mod√®le (NuSVR) √† l'aide de SHAP"""

#On installe et importe la librairie Shap
! pip install shap
import shap

# On entraine l'explainer
explainer = shap.Explainer(Nusvr.predict, X_test)

# On calcule les valeurs de Shapley
shap_values = explainer(X_test)

#On cr√©e un dataframe avec les valeurs de shap et on les ordonne
feature_names = shap_values.feature_names
shap_df = pd.DataFrame(shap_values.values, columns=feature_names)
vals = np.abs(shap_df.values).mean(0)
shap_importance = pd.DataFrame(list(zip(feature_names, vals)), columns=['col_name', 'feature_importance_vals'])
shap_importance.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True);

cat_list = ['D√©placement', 'M√©t√©o', 'D√©placement', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'Tendance',
                                      'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'M√©t√©o', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 
            'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire', 'Calendaire']

#On imprime le dataframe
result_NuSvr = shap_importance.sort_index()
result_NuSvr["cat_var"] = cat_list
result_NuSvr["importance_percent"] = result_NuSvr.feature_importance_vals.apply(lambda x :  x/result_NuSvr.feature_importance_vals.sum())

R = result_NuSvr["importance_percent"].groupby(result_NuSvr["cat_var"]).sum().sort_values(ascending = False)

plt.figure(figsize = (5,5))
plt.pie( R ,labels = R.index, autopct = '%1.0f%%', textprops={'fontsize': 14}, colors= ['tab:orange', 'tab:blue', 'tab:purple', 'tab:green'], startangle = 90, counterclock = False)
plt.title("Importance des features par cat√©gories de variables",fontdict = {'fontsize' : 20}, pad = 50)
;

#On repr√©sente graphiquement l'importance des features dans le mod√®le via un barplot
shap.summary_plot(shap_values, X_test, plot_type="bar")

#Les features sont class√©es dans l'ordre croissant d'impact sur les pr√©dictions.

#On repr√©sente les valeurs via un Beeswarm
shap.summary_plot(shap_values, max_display= 20)

#Sur le beeswarm, les features sont ordonn√©es selon leur impact sur les pr√©dictions.
#Mais on peut aussi voir dans quelle mesure les features impactent positivement ou n√©gativement le mod√®le.
#Chaque point sur le graph repr√©sente une observation. 
#L'axe horizontal repr√©sente la valeur SHAPE...
#Alors que la couleur de chaque point nous montre si une observation a une valeur sup√©rieure ou inf√©rieure, compar√©e aux autres observations.